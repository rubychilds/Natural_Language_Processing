{
 "metadata": {
  "name": "",
  "signature": "sha256:c316caf9e15672a1769cd8b8e8a234024a359e99751990b28a09d02f8134d9dc"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 2.1. Accessing Text Corpus"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "nltk.corpus.gutenberg.fileids() # all texts available"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "['austen-emma.txt',\n",
        " 'austen-persuasion.txt',\n",
        " 'austen-sense.txt',\n",
        " 'bible-kjv.txt',\n",
        " 'blake-poems.txt',\n",
        " 'bryant-stories.txt',\n",
        " 'burgess-busterbrown.txt',\n",
        " 'carroll-alice.txt',\n",
        " 'chesterton-ball.txt',\n",
        " 'chesterton-brown.txt',\n",
        " 'chesterton-thursday.txt',\n",
        " 'edgeworth-parents.txt',\n",
        " 'melville-moby_dick.txt',\n",
        " 'milton-paradise.txt',\n",
        " 'shakespeare-caesar.txt',\n",
        " 'shakespeare-hamlet.txt',\n",
        " 'shakespeare-macbeth.txt',\n",
        " 'whitman-leaves.txt']"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "emma = nltk.corpus.gutenberg.words('austen-emma.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(emma)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "192427"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import gutenberg\n",
      "for fileid in gutenberg.fileids():\n",
      "    num_chars = len(gutenberg.raw(fileid)) # gives us the contents of file with no linguistic processing. Taking the length we have no. of letters in text\n",
      "    num_words = len(gutenberg.words(fileid))\n",
      "    num_sents = len(gutenberg.sents(fileid))\n",
      "    num_vocab = len(set([w.lower() for w in gutenberg.words(fileid)]))\n",
      "    print int(num_chars/num_words), int(num_words/num_sents), int(num_words/num_vocab), fileid\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4 21 26 austen-emma.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 23 16 austen-persuasion.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 23 22 austen-sense.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33 79 bible-kjv.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 18 5 blake-poems.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 17 14 bryant-stories.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 17 12 burgess-busterbrown.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 16 12 carroll-alice.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 17 11 chesterton-ball.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 19 11 chesterton-brown.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 16 10 chesterton-thursday.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 17 24 edgeworth-parents.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 24 15 melville-moby_dick.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 52 10 milton-paradise.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11 8 shakespeare-caesar.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12 7 shakespeare-hamlet.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12 6 shakespeare-macbeth.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 35 12 whitman-leaves.txt\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "macbeth_sentences = gutenberg.sents('shakespeare-macbeth.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "macbeth_sentences"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "[['[', 'The', 'Tragedie', 'of', 'Macbeth', 'by', 'William', 'Shakespeare', '1603', ']'], ['Actus', 'Primus', '.'], ...]"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "macbeth_sentences[1037]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "['Good', 'night', ',', 'and', 'better', 'health', 'Attend', 'his', 'Maiesty']"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "longest_length = max([len(s) for s in macbeth_sentences]) # longest sentence length"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print [s for s in macbeth_sentences if len(s) == longest_length][:10] # retrieve longest sentence"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[['Doubtfull', 'it', 'stood', ',', 'As', 'two', 'spent', 'Swimmers', ',', 'that', 'doe', 'cling', 'together', ',', 'And', 'choake', 'their', 'Art', ':', 'The', 'mercilesse', 'Macdonwald', '(', 'Worthie', 'to', 'be', 'a', 'Rebell', ',', 'for', 'to', 'that', 'The', 'multiplying', 'Villanies', 'of', 'Nature', 'Doe', 'swarme', 'vpon', 'him', ')', 'from', 'the', 'Westerne', 'Isles', 'Of', 'Kernes', 'and', 'Gallowgrosses', 'is', 'supply', \"'\", 'd', ',', 'And', 'Fortune', 'on', 'his', 'damned', 'Quarry', 'smiling', ',', 'Shew', \"'\", 'd', 'like', 'a', 'Rebells', 'Whore', ':', 'but', 'all', \"'\", 's', 'too', 'weake', ':', 'For', 'braue', 'Macbeth', '(', 'well', 'hee', 'deserues', 'that', 'Name', ')', 'Disdayning', 'Fortune', ',', 'with', 'his', 'brandisht', 'Steele', ',', 'Which', 'smoak', \"'\", 'd', 'with', 'bloody', 'execution', '(', 'Like', 'Valours', 'Minion', ')', 'caru', \"'\", 'd', 'out', 'his', 'passage', ',', 'Till', 'hee', 'fac', \"'\", 'd', 'the', 'Slaue', ':', 'Which', 'neu', \"'\", 'r', 'shooke', 'hands', ',', 'nor', 'bad', 'farwell', 'to', 'him', ',', 'Till', 'he', 'vnseam', \"'\", 'd', 'him', 'from', 'the', 'Naue', 'toth', \"'\", 'Chops', ',', 'And', 'fix', \"'\", 'd', 'his', 'Head', 'vpon', 'our', 'Battlements']]\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import webtext #Webtext"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for fileid in webtext.fileids():\n",
      "    print fileid, webtext.raw(fileid)[:65]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "firefox.txt "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Cookie Manager: \"Don't allow sites that set removed cookies to se\n",
        "grail.txt SCENE 1: [wind] [clop clop clop] \n",
        "KING ARTHUR: Whoa there!  [clop\n",
        "overheard.txt White guy: So, do you have any plans for this evening?\n",
        "Asian girl\n",
        "pirates.txt "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "PIRATES OF THE CARRIBEAN: DEAD MAN'S CHEST, by Ted Elliott & Terr\n",
        "singles.txt 25 SEXY MALE, seeks attrac older single lady, for discreet encoun\n",
        "wine.txt Lovely delicate, fragrant Rhone wine. Polished leather and strawb\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import nps_chat #Chat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chatroom = nps_chat.posts('10-19-20s_706posts.xml')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import brown # Brown Corpus"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "brown.categories()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "['adventure',\n",
        " 'belles_lettres',\n",
        " 'editorial',\n",
        " 'fiction',\n",
        " 'government',\n",
        " 'hobbies',\n",
        " 'humor',\n",
        " 'learned',\n",
        " 'lore',\n",
        " 'mystery',\n",
        " 'news',\n",
        " 'religion',\n",
        " 'reviews',\n",
        " 'romance',\n",
        " 'science_fiction']"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "brown.words(categories = 'news')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "brown.words(fileids=['cg22'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "['Does', 'our', 'society', 'have', 'a', 'runaway', ',', ...]"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "brown.sents(categories=['news','editorial','reviews'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "news_text = brown.words(categories='news')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fdist = nltk.FreqDist([w.lower() for w in news_text])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "modals= ['can','could','may','might','must','will']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for m in modals:\n",
      "    print m + ': ', fdist[m],"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "can:  94 could:  87 may:  93 might:  38 must:  53 will:  389\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfd = nltk.ConditionalFreqDist(\n",
      "    (genre, word)\n",
      "    for genre in brown.categories()\n",
      "    for word in brown.words(categories=genre))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "genres = ['news', 'religion', 'hobbies', 'science_fiction', 'romance', 'humor']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "modals = ['can','could','may','might','must','will']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfd.tabulate(conditions=genres, samples=modals)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                 can could  may might must will\n",
        "           news   93   86   66   38   50  389\n",
        "       religion   82   59   78   12   54   71\n",
        "        hobbies  268   58  131   22   83  264\n",
        "science_fiction   16   49    4   12    8   16\n",
        "        romance   74  193   11   51   45   43\n",
        "          humor   16   30    8    8    9   13\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import reuters #Reuters Corpus"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print reuters.fileids()[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['test/14826', 'test/14828', 'test/14829', 'test/14832', 'test/14833', 'test/14839', 'test/14840', 'test/14841', 'test/14842', 'test/14843']\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reuters.categories('training/9865')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "['barley', 'corn', 'grain', 'wheat']"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reuters.categories(['training/9865','training/9880'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "['barley', 'corn', 'grain', 'money-fx', 'wheat']"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print reuters.fileids('barley')[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['test/15618', 'test/15649', 'test/15676', 'test/15728', 'test/15871', 'test/15875', 'test/15952', 'test/17767', 'test/17769', 'test/18024']\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print reuters.fileids(['barley','corn'])[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['test/14832', 'test/14858', 'test/15033', 'test/15043', 'test/15106', 'test/15287', 'test/15341', 'test/15618', 'test/15648', 'test/15649']\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reuters.words('training/9865')[:14]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "['FRENCH',\n",
        " 'FREE',\n",
        " 'MARKET',\n",
        " 'CEREAL',\n",
        " 'EXPORT',\n",
        " 'BIDS',\n",
        " 'DETAILED',\n",
        " 'French',\n",
        " 'operators',\n",
        " 'have',\n",
        " 'requested',\n",
        " 'licences',\n",
        " 'to',\n",
        " 'export']"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reuters.words(['training/9865', 'training/9880'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "['FRENCH', 'FREE', 'MARKET', 'CEREAL', 'EXPORT', ...]"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reuters.words(categories='barley')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "['FRENCH', 'FREE', 'MARKET', 'CEREAL', 'EXPORT', ...]"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reuters.words(categories=['barley','corn'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "['THAI', 'TRADE', 'DEFICIT', 'WIDENS', 'IN', 'FIRST', ...]"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import inaugural # Inagural CorpusReader"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print inaugural.fileids()[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['1789-Washington.txt', '1793-Washington.txt', '1797-Adams.txt', '1801-Jefferson.txt', '1805-Jefferson.txt', '1809-Madison.txt', '1813-Madison.txt', '1817-Monroe.txt', '1821-Monroe.txt', '1825-Adams.txt']\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print [fileid[:4] for fileid in inaugural.fileids()][:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['1789', '1793', '1797', '1801', '1805', '1809', '1813', '1817', '1821', '1825']\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfd = nltk.ConditionalFreqDist(\n",
      "            (target, fileid[:4])\n",
      "            for fileid in inaugural.fileids()\n",
      "            for w in inaugural.words(fileid)\n",
      "            for target in ['america','citizen']\n",
      "            if w.lower().startswith(target)\n",
      "            )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfd.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.corpus.cess_esp.words() # Corpus in other langauges"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "['El', 'grupo', 'estatal', 'Electricit\\xe9_de_France', ...]"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.corpus.floresta.words()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "['Um', 'revivalismo', 'refrescante', 'O', '7_e_Meio', ...]"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.corpus.indian.words('hindi.pos')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "['\\xe0\\xa4\\xaa\\xe0\\xa5\\x82\\xe0\\xa4\\xb0\\xe0\\xa5\\x8d\\xe0\\xa4\\xa3', '\\xe0\\xa4\\xaa\\xe0\\xa5\\x8d\\xe0\\xa4\\xb0\\xe0\\xa4\\xa4\\xe0\\xa4\\xbf\\xe0\\xa4\\xac\\xe0\\xa4\\x82\\xe0\\xa4\\xa7', ...]"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print nltk.corpus.udhr.fileids()[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['Abkhaz-Cyrillic+Abkh', 'Abkhaz-UTF8', 'Achehnese-Latin1', 'Achuar-Shiwiar-Latin1', 'Adja-UTF8', 'Afaan_Oromo_Oromiffa-Latin1', 'Afrikaans-Latin1', 'Aguaruna-Latin1', 'Akuapem_Twi-UTF8', 'Albanian_Shqip-Latin1']\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.corpus.udhr.words('Javanese-Latin1')[11:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "[u'Saben', u'umat', u'manungsa', u'lair', u'kanthi', ...]"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import udhr # UDHR - Universal Declaration of Human Rights"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "languages = ['Chickasaw', 'English', 'German_Deutsch', 'Greenlandic_Inuktikut','Hungarian_Magyar', 'Breton']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfd = nltk.ConditionalFreqDist(\n",
      "            (lang,len(word))\n",
      "            for lang in languages\n",
      "            for word in udhr.words(lang + '-Latin1'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfd.plot(cumulative=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import gutenberg\n",
      "raw = gutenberg.raw('burgess-busterbrown.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "raw[1:20]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 54,
       "text": [
        "'The Adventures of B'"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "words = gutenberg.words('burgess-busterbrown.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "words[1:20]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 56,
       "text": [
        "['The',\n",
        " 'Adventures',\n",
        " 'of',\n",
        " 'Buster',\n",
        " 'Bear',\n",
        " 'by',\n",
        " 'Thornton',\n",
        " 'W',\n",
        " '.',\n",
        " 'Burgess',\n",
        " '1920',\n",
        " ']',\n",
        " 'I',\n",
        " 'BUSTER',\n",
        " 'BEAR',\n",
        " 'GOES',\n",
        " 'FISHING',\n",
        " 'Buster',\n",
        " 'Bear']"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sents = gutenberg.sents('burgess-busterbrown.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print sents[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['I']\n"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Explanation of loading your own corpus\n",
      "#from nltk.corpus import PlaintextCorpusReader\n",
      "#corpus_root = 'file_directory' # location of passed in corpus\n",
      "#wordlists = PlaintextCorpusReader(corpus_root, '.*') # define subdirectories\n",
      "#wordlists.fileids()\n",
      "#wordlists.words('connectives')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Explanation of BracketParseCorpus\n",
      "corpus_root = ''\n",
      "file_pattern = r''\n",
      "ptb = BracketParseCorpusReader(corpus_root, file_pattern)\n",
      "ptb.fields()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'BracketParseCorpusReader' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-61-ff0dc84dab88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcorpus_root\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfile_pattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mptb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBracketParseCorpusReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_root\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_pattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mptb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'BracketParseCorpusReader' is not defined"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 2.2 Conditional Frequency Distribution"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text = ['The','Fulton','County','Grand','Jury','said']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pairs = [('news','The'), ('news','Fulton'),('news','County')]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import brown"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfd = nltk.ConditionalFreqDist((genre,word) for genre in brown.categories() \n",
      "                               for word in brown.words(categories=genre))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "genre_word = [(genre,word) for genre in ['news','romance']\n",
      "                               for word in brown.words(categories=genre)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print genre_word[:4] # begins with ('news', word), then at end of list ('romance',word)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('news', 'The'), ('news', 'Fulton'), ('news', 'County'), ('news', 'Grand')]\n"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "genre_word[-4:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 69,
       "text": [
        "[('romance', 'afraid'),\n",
        " ('romance', 'not'),\n",
        " ('romance', \"''\"),\n",
        " ('romance', '.')]"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfd = nltk.ConditionalFreqDist(genre_word) # Collections of FreqDist"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfd.conditions() "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 71,
       "text": [
        "['news', 'romance']"
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfd['news']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 72,
       "text": [
        "<FreqDist with 14394 samples and 100554 outcomes>"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfd['romance']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 73,
       "text": [
        "<FreqDist with 8452 samples and 70022 outcomes>"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import inaugural"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfd = nltk.ConditionalFreqDist((target,fileid[:4]) for fileid in inaugural.fileids()\n",
      "                               for w in inaugural.words(fileid)\n",
      "                               for target in ['america', 'citizen']\n",
      "                               if w.lower().startswith(target))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfd.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import udhr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "languages = ['Chicksaw','English','German_Dutsch','Hungarian_Magyar', 'Ibibio_Efik']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#cfd = nltk.ConditionalFreqDist((lang, len(word)) for lang in languages\n",
      " #                              for word in udhr.words(lang + '-Latin1'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "days = ['Monday','Tuesday','Wednesday','Thursday','Friday']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfd = nltk.ConditionalFreqDist((genre,word) for genre in ['news','romance']\n",
      "                               for word in brown.words(categories=genre))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfd.tabulate(samples = days)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "        Monday Tuesday Wednesday Thursday Friday\n",
        "   news   54   43   22   20   41\n",
        "romance    2    3    3    1    3\n"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Generating Random Words with Bigrams"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sent = ['In','the','beginning','Science','created','the','earth','and','the','planets']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "nltk.bigrams(sent)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 83,
       "text": [
        "[('In', 'the'),\n",
        " ('the', 'beginning'),\n",
        " ('beginning', 'Science'),\n",
        " ('Science', 'created'),\n",
        " ('created', 'the'),\n",
        " ('the', 'earth'),\n",
        " ('earth', 'and'),\n",
        " ('and', 'the'),\n",
        " ('the', 'planets')]"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def generate_model(cfdist,word, num=15):\n",
      "    for i in range(num):\n",
      "        print word\n",
      "        word = cfdist[word].max()\n",
      "text = nltk.corpus.genesis.words('english-kjv.txt')\n",
      "bigrams = nltk.bigrams(text)\n",
      "cfd = nltk.ConditionalFreqDist(bigrams)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print cfd['living']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<FreqDist: u'creature': 7, u'thing': 4, u'substance': 2, u',': 1, u'.': 1, u'soul': 1>\n"
       ]
      }
     ],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "generate_model(cfd,'living')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "living\n",
        "creature\n",
        "that\n",
        "he\n",
        "said\n",
        ",\n",
        "and\n",
        "the\n",
        "land\n",
        "of\n",
        "the\n",
        "land\n",
        "of\n",
        "the\n",
        "land\n"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 2.3. Reusing Code"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def lexical_diversity(text):\n",
      "    return len(text)/len(set(text))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def lexical_diversity(my_text):\n",
      "    word_count = len(text)\n",
      "    vocab_size = len(set(text))\n",
      "    diversity = word_count/vocab_size\n",
      "    return diversity"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 89
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 2.4. Lexical Resources"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk.corpus"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def unusual_words(text):\n",
      "    text_vocab = set(w.lower() for w in text if w.isalpha())\n",
      "    english_vocab = set(w.lower() for w in nltk.corpus.words.words())\n",
      "    unusual = text_vocab.difference(english_vocab)\n",
      "    return sorted(unusual)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print unusual_words(nltk.corpus.gutenberg.words('austen-sense.txt') )[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['abbeyland', 'abhorred', 'abilities', 'abounded', 'abridgement', 'abused', 'abuses', 'accents', 'accepting', 'accommodations']\n"
       ]
      }
     ],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print unusual_words(nltk.corpus.nps_chat.words())[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['aaaaaaaaaaaaaaaaa', 'aaahhhh', 'abortions', 'abou', 'abourted', 'abs', 'ack', 'acros', 'actualy', 'adams']\n"
       ]
      }
     ],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import stopwords"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print stopwords.words('english')[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your']\n"
       ]
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def content_fraction(text):\n",
      "    stopwords = nltk.corpus.stopwords.words('english')\n",
      "    content = [w for w in text if w.lower() not in stopwords] # removes stopwords\n",
      "    return len(content)/float(len(text))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "content_fraction(nltk.corpus.reuters.words())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 100,
       "text": [
        "0.7364374824583169"
       ]
      }
     ],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "puzzle_letters = nltk.FreqDist('egivrvonl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "obligatory = 'r'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word_list = nltk.corpus.words.words()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print [w for w in word_list if len(w) >= 6 and obligatory in w and nltk.FreqDist(w) <= puzzle_letters][:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['glover', 'gorlin', 'govern', 'grovel', 'ignore', 'involver', 'lienor', 'linger', 'longer', 'lovering']\n"
       ]
      }
     ],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "names = nltk.corpus.names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "names.fileids()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 108,
       "text": [
        "['female.txt', 'male.txt']"
       ]
      }
     ],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "male_names = names.words('male.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 109
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "female_names = names.words('female.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "male_names[1:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 111,
       "text": [
        "['Aaron',\n",
        " 'Abbey',\n",
        " 'Abbie',\n",
        " 'Abbot',\n",
        " 'Abbott',\n",
        " 'Abby',\n",
        " 'Abdel',\n",
        " 'Abdul',\n",
        " 'Abdulkarim']"
       ]
      }
     ],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print [w for w in male_names if w in female_names][:10] # names for both genders"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['Abbey', 'Abbie', 'Abby', 'Addie', 'Adrian', 'Adrien', 'Ajay', 'Alex', 'Alexis', 'Alfie']\n"
       ]
      }
     ],
     "prompt_number": 112
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfd = nltk.ConditionalFreqDist((fileid,name[-1]) for fileid in names.fileids() for name in names.words(fileid))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfd.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 114
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Pronouncing dictionary"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "entries = nltk.corpus.cmudict.entries()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 116
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(entries)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 117,
       "text": [
        "133737"
       ]
      }
     ],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for entry in entries[39943:39951]: # word, then phonetic codes - distinct labels for each constrastive sound\n",
      "    print entry"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('explorer', ['IH0', 'K', 'S', 'P', 'L', 'AO1', 'R', 'ER0'])\n",
        "('explorers', ['IH0', 'K', 'S', 'P', 'L', 'AO1', 'R', 'ER0', 'Z'])\n",
        "('explores', ['IH0', 'K', 'S', 'P', 'L', 'AO1', 'R', 'Z'])\n",
        "('exploring', ['IH0', 'K', 'S', 'P', 'L', 'AO1', 'R', 'IH0', 'NG'])\n",
        "('explosion', ['IH0', 'K', 'S', 'P', 'L', 'OW1', 'ZH', 'AH0', 'N'])\n",
        "('explosions', ['IH0', 'K', 'S', 'P', 'L', 'OW1', 'ZH', 'AH0', 'N', 'Z'])\n",
        "('explosive', ['IH0', 'K', 'S', 'P', 'L', 'OW1', 'S', 'IH0', 'V'])\n",
        "('explosively', ['EH2', 'K', 'S', 'P', 'L', 'OW1', 'S', 'IH0', 'V', 'L', 'IY0'])\n"
       ]
      }
     ],
     "prompt_number": 118
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for word, pron in entries:\n",
      "    if len(pron) == 3: # has 3 phones\n",
      "        ph1, ph2, ph3 = pron # assigns to 3 new variables\n",
      "        if ph1 == 'P' and ph3 == 'T' : \n",
      "            print word, ph2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "pait EY1\n",
        "pat AE1\n",
        "pate EY1\n",
        "patt AE1\n",
        "peart ER1\n",
        "peat IY1\n",
        "peet IY1\n",
        "peete IY1\n",
        "pert ER1\n",
        "pet EH1\n",
        "pete IY1\n",
        "pett EH1\n",
        "piet IY1\n",
        "piette IY1\n",
        "pit IH1\n",
        "pitt IH1\n",
        "pot AA1\n",
        "pote OW1\n",
        "pott AA1\n",
        "pout AW1\n",
        "puett UW1\n",
        "purt ER1\n",
        "put UH1\n",
        "putt AH1\n"
       ]
      }
     ],
     "prompt_number": 119
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "syllable = ['N','IHO','K','S']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 120
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[word for word, pron in entries if pron[-4:] == syllable] # No longer produces examples as shown in the %bookmar"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 121,
       "text": [
        "[]"
       ]
      }
     ],
     "prompt_number": 121
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[w for w, pron in entries if pron[-1]=='M' and w[-1] == 'n']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 122,
       "text": [
        "['autumn', 'column', 'condemn', 'damn', 'goddamn', 'hymn', 'solemn']"
       ]
      }
     ],
     "prompt_number": 122
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sorted(set(w[:2] for w, pron in entries if pron[0] == 'N' and w[0] !='n'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 123,
       "text": [
        "['gn', 'kn', 'mn', 'pn']"
       ]
      }
     ],
     "prompt_number": 123
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def stress(pron):\n",
      "    return [char for phone in pron for char in phone if char.isdigit()] #1 is primiary stress, secondary - 2, no stress 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print [w for w, pron in entries if stress(pron) == ['0','1','0','2','0']][:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['abbreviated', 'abbreviated', 'abbreviating', 'accelerated', 'accelerating', 'accelerator', 'accelerators', 'accentuated', 'accentuating', 'accommodated']\n"
       ]
      }
     ],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print [(w,pron) for w, pron in entries if stress(pron) == ['0','2','0','1','0']][:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('abbreviation', ['AH0', 'B', 'R', 'IY2', 'V', 'IY0', 'EY1', 'SH', 'AH0', 'N']), ('abbreviations', ['AH0', 'B', 'R', 'IY2', 'V', 'IY0', 'EY1', 'SH', 'AH0', 'N', 'Z']), ('abomination', ['AH0', 'B', 'AA2', 'M', 'AH0', 'N', 'EY1', 'SH', 'AH0', 'N']), ('abortifacient', ['AH0', 'B', 'AO2', 'R', 'T', 'AH0', 'F', 'EY1', 'SH', 'AH0', 'N', 'T']), ('abortifacients', ['AH0', 'B', 'AO2', 'R', 'T', 'AH0', 'F', 'EY1', 'SH', 'AH0', 'N', 'T', 'S']), ('academicians', ['AH0', 'K', 'AE2', 'D', 'AH0', 'M', 'IH1', 'SH', 'AH0', 'N', 'Z']), ('accommodation', ['AH0', 'K', 'AA2', 'M', 'AH0', 'D', 'EY1', 'SH', 'AH0', 'N']), ('accommodations', ['AH0', 'K', 'AA2', 'M', 'AH0', 'D', 'EY1', 'SH', 'AH0', 'N', 'Z']), ('accreditation', ['AH0', 'K', 'R', 'EH2', 'D', 'AH0', 'T', 'EY1', 'SH', 'AH0', 'N']), ('accreditations', ['AH0', 'K', 'R', 'EH2', 'D', 'AH0', 'D', 'EY1', 'SH', 'AH0', 'N', 'Z'])]\n"
       ]
      }
     ],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p3 = [(pron[0] + '-' +pron[2] , word)\n",
      "      for word, pron in entries\n",
      "      if pron[0] == 'P' and len(pron) == 3] # finds all words with three sounds and groups according to their first and last sounds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfd = nltk.ConditionalFreqDist(p3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 128
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for template in cfd.conditions():\n",
      "    if len(cfd[template]) > 10:\n",
      "        words = cfd[template].keys()\n",
      "        wordList = ' '.join(words)\n",
      "        print template, wordList[:70] +  \"...\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "P-CH patch pautsch peach perch petsch petsche piche piech pietsch pitch pit...\n",
        "P-K pac pack paek paik pak pake paque peak peake pech peck peek perc perk ...\n",
        "P-L pall pahl pail paille pal pale paul paule paull peal peale pearl pearl...\n",
        "P-N paign pain paine pan pane pawn payne peine pen penh penn pin pine pinn...\n",
        "P-P paap paape pap pape papp paup peep pep pip pipe pipp poop pop pope pop...\n",
        "P-R paar pair par pare parr pear peer pier poor poore por pore porr pour...\n",
        "P-S puss pace pass pasts peace pearse pease perce pers perse pesce piece p...\n",
        "P-T pait pat pate patt peart peat peet peete pert pet pete pett piet piett...\n",
        "P-UW1 peru peugh pew plew plue prew pru prue prugh pshew pugh...\n",
        "P-Z p's p.'s p.s pais paiz pao's pas pause paws pays paz peas pease pei's ...\n"
       ]
      }
     ],
     "prompt_number": 129
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prondict = nltk.corpus.cmudict.dict()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prondict['fire']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 131,
       "text": [
        "[['F', 'AY1', 'ER0'], ['F', 'AY1', 'R']]"
       ]
      }
     ],
     "prompt_number": 131
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prondict['blog'] = [['B','L','AAI','G']] # first we get a key error in asking for 'blog'. 'blog' missing from pronouncing dictionary.\n",
      "# Doesn't affect corpus, addition is temp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 132
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text = ['natural', 'language', 'processing']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 133
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[ph for w in text for ph in prondict[w][0]] # takes each word and looks this up in pronounciation dictionary"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 134,
       "text": [
        "['N',\n",
        " 'AE1',\n",
        " 'CH',\n",
        " 'ER0',\n",
        " 'AH0',\n",
        " 'L',\n",
        " 'L',\n",
        " 'AE1',\n",
        " 'NG',\n",
        " 'G',\n",
        " 'W',\n",
        " 'AH0',\n",
        " 'JH',\n",
        " 'P',\n",
        " 'R',\n",
        " 'AA1',\n",
        " 'S',\n",
        " 'EH0',\n",
        " 'S',\n",
        " 'IH0',\n",
        " 'NG']"
       ]
      }
     ],
     "prompt_number": 134
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Comparative Word Lists\n",
      "from nltk.corpus import swadesh"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 135
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "swadesh.fileids()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 136,
       "text": [
        "['be',\n",
        " 'bg',\n",
        " 'bs',\n",
        " 'ca',\n",
        " 'cs',\n",
        " 'cu',\n",
        " 'de',\n",
        " 'en',\n",
        " 'es',\n",
        " 'fr',\n",
        " 'hr',\n",
        " 'it',\n",
        " 'la',\n",
        " 'mk',\n",
        " 'nl',\n",
        " 'pl',\n",
        " 'pt',\n",
        " 'ro',\n",
        " 'ru',\n",
        " 'sk',\n",
        " 'sl',\n",
        " 'sr',\n",
        " 'sw',\n",
        " 'uk']"
       ]
      }
     ],
     "prompt_number": 136
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print swadesh.words('en')[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['I', 'you (singular), thou', 'he', 'we', 'you (plural)', 'they', 'this', 'that', 'here', 'there']\n"
       ]
      }
     ],
     "prompt_number": 137
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fr2en = swadesh.entries(['fr','en']) # gives french and english pairings"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 138
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fr2en[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 139,
       "text": [
        "[('je', 'I'),\n",
        " ('tu, vous', 'you (singular), thou'),\n",
        " ('il', 'he'),\n",
        " ('nous', 'we'),\n",
        " ('vous', 'you (plural)'),\n",
        " ('ils, elles', 'they'),\n",
        " ('ceci', 'this'),\n",
        " ('cela', 'that'),\n",
        " ('ici', 'here'),\n",
        " ('l\\xc3\\xa0', 'there')]"
       ]
      }
     ],
     "prompt_number": 139
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "translate = dict(fr2en) # maps french keys to english words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 140
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "translate['chien']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 141,
       "text": [
        "'dog'"
       ]
      }
     ],
     "prompt_number": 141
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "translate['jeter']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 142,
       "text": [
        "'throw'"
       ]
      }
     ],
     "prompt_number": 142
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "de2en = swadesh.entries(['de','en']) # german-english"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 143
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "es2en = swadesh.entries(['es','en'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 144
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "translate.update(dict(de2en))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 145
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "translate.update(dict(es2en))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 146
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "translate['Hund']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 147,
       "text": [
        "'dog'"
       ]
      }
     ],
     "prompt_number": 147
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "translate['perro']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 148,
       "text": [
        "'dog'"
       ]
      }
     ],
     "prompt_number": 148
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "languages = ['en','de','nl','es','fr','pt','la']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 149
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in [139,140,141,142]:\n",
      "    print swadesh.entries(languages)[i]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('say', 'sagen', 'zeggen', 'decir', 'dire', 'dizer', 'dicere')\n",
        "('sing', 'singen', 'zingen', 'cantar', 'chanter', 'cantar', 'canere')\n",
        "('play', 'spielen', 'spelen', 'jugar', 'jouer', 'jogar, brincar', 'ludere')\n",
        "('float', 'schweben', 'zweven', 'flotar', 'flotter', 'flutuar, boiar', 'fluctuare')\n"
       ]
      }
     ],
     "prompt_number": 150
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Shoe box and Toolbox Lexicons"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 151
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import toolbox # TOOLBOX consists of a collection of entries where each entry is made up of one or more fields"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 152
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "toolbox.entries('rotokas.dic')[:10] # second part of tuple to indicate that the part of speech."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 154,
       "text": [
        "[('kaa',\n",
        "  [('ps', 'V'),\n",
        "   ('pt', 'A'),\n",
        "   ('ge', 'gag'),\n",
        "   ('tkp', 'nek i pas'),\n",
        "   ('dcsv', 'true'),\n",
        "   ('vx', '1'),\n",
        "   ('sc', '???'),\n",
        "   ('dt', '29/Oct/2005'),\n",
        "   ('ex', 'Apoka ira kaaroi aioa-ia reoreopaoro.'),\n",
        "   ('xp', 'Kaikai i pas long nek bilong Apoka bikos em i kaikai na toktok.'),\n",
        "   ('xe', 'Apoka is gagging from food while talking.')]),\n",
        " ('kaa',\n",
        "  [('ps', 'V'),\n",
        "   ('pt', 'B'),\n",
        "   ('ge', 'strangle'),\n",
        "   ('tkp', 'pasim nek'),\n",
        "   ('arg', 'O'),\n",
        "   ('vx', '2'),\n",
        "   ('dt', '07/Oct/2006'),\n",
        "   ('ex', 'Rera rauroro rera kaarevoi.'),\n",
        "   ('xp', 'Em i holim pas em na nekim em.'),\n",
        "   ('xe', 'He is holding him and strangling him.'),\n",
        "   ('ex', 'Iroiro-ia oirato okoearo kaaivoi uvare rirovira kaureoparoveira.'),\n",
        "   ('xp', 'Ol i pasim nek bilong man long rop bikos em i save bikhet tumas.'),\n",
        "   ('xe',\n",
        "    \"They strangled the man's neck with rope because he was very stubborn and arrogant.\"),\n",
        "   ('ex',\n",
        "    'Oirato okoearo kaaivoi iroiro-ia. Uva viapau uvuiparoi ra vovouparo uva kopiiroi.'),\n",
        "   ('xp',\n",
        "    'Ol i pasim nek bilong man long rop. Olsem na em i no pulim win olsem na em i dai.'),\n",
        "   ('xe',\n",
        "    \"They strangled the man's neck with a rope. And he couldn't breathe and he died.\")]),\n",
        " ('kaa',\n",
        "  [('ps', 'N'),\n",
        "   ('pt', 'MASC'),\n",
        "   ('cl', 'isi'),\n",
        "   ('ge', 'cooking banana'),\n",
        "   ('tkp', 'banana bilong kukim'),\n",
        "   ('pt', 'itoo'),\n",
        "   ('sf', 'FLORA'),\n",
        "   ('dt', '12/Aug/2005'),\n",
        "   ('ex', 'Taeavi iria kaa isi kovopaueva kaparapasia.'),\n",
        "   ('xp', 'Taeavi i bin planim gaden banana bilong kukim tasol long paia.'),\n",
        "   ('xe', 'Taeavi planted banana in order to cook it.')]),\n",
        " ('kaakaaro',\n",
        "  [('ps', 'N'),\n",
        "   ('pt', 'NT'),\n",
        "   ('ge', 'mixture'),\n",
        "   ('tkp', '???'),\n",
        "   ('eng', 'mixtures'),\n",
        "   ('eng', 'charm used to keep married men and women youthful and attractive'),\n",
        "   ('cmt',\n",
        "    'Check vowel length. Is it kaakaaro or kaakaro? Does lexeme have suffix, -aro or -ro?'),\n",
        "   ('dt', '20/Nov/2006'),\n",
        "   ('ex',\n",
        "    'Kaakaroto ira purapaiveira aue iava opita, voeao-pa airepa oraouirara, ra va aiopaive.'),\n",
        "   ('xp',\n",
        "    'Kokonas ol i save wokim long ol kain samting bilong ol nupela marit, bai ol i ken kaikai.'),\n",
        "   ('xe', 'Mixtures are made from coconut for newlyweds, who eat them.')]),\n",
        " ('kaakaaviko',\n",
        "  [('ps', 'N'),\n",
        "   ('pt', 'FEM'),\n",
        "   ('ge', 'type of beetle'),\n",
        "   ('tkp', '???'),\n",
        "   ('nt', 'round beetle like Mexican bean beetle'),\n",
        "   ('dt', '10/Feb/2005'),\n",
        "   ('sf', 'FAUNA.INSECT'),\n",
        "   ('ex', 'Kaakaaviko kare oea binara touaveira vara tapo piupaiveira.'),\n",
        "   ('xp',\n",
        "    'Kaakaaviko em i wanpela kain insect em i save istap long ol bin or na long kain lip.'),\n",
        "   ('xe', '???'),\n",
        "   ('ex', 'Kaakaaviko kare oea raviriro kouro piupaiveira.'),\n",
        "   ('xp', 'Em i wanpela kain weevil i save bagarapim ol bin.'),\n",
        "   ('xe', '??? damages up beans.')]),\n",
        " ('kaakaavo',\n",
        "  [('rt', 'kaavo'),\n",
        "   ('ps', '???'),\n",
        "   ('rdp', 'partial'),\n",
        "   ('ge', 'white'),\n",
        "   ('tkp', 'wait'),\n",
        "   ('sc', '???'),\n",
        "   ('cmt', \"What's the part of speech?\"),\n",
        "   ('dt', '29/Oct/2005'),\n",
        "   ('ex',\n",
        "    'Kaakaaro oa purapaiveira varauraro tokipasia aue iava opita ora vegoara iava oirara iava ora riakova kaakaaro.'),\n",
        "   ('xp',\n",
        "    'Ol i save wokim out long kokonas coconut na ol lip na skin blong ol diwai.'),\n",
        "   ('xe', '???'),\n",
        "   ('ex', 'Varoa kaakaavopa popotepa ragai varo.'),\n",
        "   ('xp', 'Em white lap lap blong mi.'),\n",
        "   ('xe', \"That's my white laplap.\"),\n",
        "   ('ex', 'Vaoia evaova kaakaavopaova.'),\n",
        "   ('xp', 'Dispela diwai em i waitpela.'),\n",
        "   ('xe', 'This tree is white.'),\n",
        "   ('ex',\n",
        "    'Rarasoria kaakaavoto ira Amerika iava urioroera vo kovosia rupairara voaro.'),\n",
        "   ('xp',\n",
        "    'Rarason em i wait man em i bin kam long Amerika na kam wok long hap bilong ol bilak man.'),\n",
        "   ('xe', 'Rarason is a white man who came from America ???.')]),\n",
        " ('kaakaoko',\n",
        "  [('ps', 'N'),\n",
        "   ('pt', '???'),\n",
        "   ('ge', 'type of beetle'),\n",
        "   ('tkp', 'binatang'),\n",
        "   ('sf', 'FAUNA.INSECT'),\n",
        "   ('cmt', 'Is it kaakaoko or kaakauko?'),\n",
        "   ('dt', '08/Feb/2005'),\n",
        "   ('ex', 'Kaakaoko vuri gesito./Kaakauko vurisi gesiva.'),\n",
        "   ('xp', '???'),\n",
        "   ('xe', 'Kaakauko em i wanpela binatang.')]),\n",
        " ('kaakasi',\n",
        "  [('rt', '???'),\n",
        "   ('ps', 'V'),\n",
        "   ('pt', 'A'),\n",
        "   ('ge', 'hot'),\n",
        "   ('tkp', 'hot'),\n",
        "   ('vx', '1'),\n",
        "   ('sc', '???'),\n",
        "   ('cmt',\n",
        "    \"Vowel length can't possibly be right. Or is the vowel of kaasi long?\"),\n",
        "   ('dt', '29/Oct/2005'),\n",
        "   ('ex', 'Upiriko pitoka kaakasipai.'),\n",
        "   ('xp', 'Sospen kaukau em i hot tru.'),\n",
        "   ('xe', 'The saucepan of sweet potatos is really hot.'),\n",
        "   ('ex',\n",
        "    'Kaukau pitoka rirovira rutu kaakasipai uvare riro kasia tuitui kasi oripiro.'),\n",
        "   ('xp', 'Sospen kaukau em i hot tru bikos em i tan long bikpela paia.'),\n",
        "   ('xe', '???')]),\n",
        " ('kaakau',\n",
        "  [('ps', 'N'),\n",
        "   ('pt', 'FEM'),\n",
        "   ('ge', 'dog'),\n",
        "   ('tkp', 'dok'),\n",
        "   ('dt', '17/Jul/2005'),\n",
        "   ('ex', 'Kaakau voresiurava toupa aue kokoto ora kokopi.'),\n",
        "   ('xp', 'Dog i gat fopela lek bilong em na em i teleblonge.'),\n",
        "   ('xe', 'Dogs are four-footed ???.'),\n",
        "   ('ex', 'Revisa riro kaakau raguito.'),\n",
        "   ('xp', 'Revisa em i man bilong lukautim dok.'),\n",
        "   ('xe', 'Revisa is a big dog lover.'),\n",
        "   ('ex', 'Rake ora Jon kaakau kare ousia avasie.'),\n",
        "   ('xp', 'Rake wantaim Jon ol i go kisim ol wail dok.'),\n",
        "   ('xe', 'Rake and John went to get wild dogs.')]),\n",
        " ('kaakauko',\n",
        "  [('ps', 'N'),\n",
        "   ('pt', 'MASC'),\n",
        "   ('ge', 'gray weevil'),\n",
        "   ('tkp', 'wanpela kain binatang'),\n",
        "   ('sf', 'FAUNA.INSECT'),\n",
        "   ('nt', 'pictured on PNG postage stamp'),\n",
        "   ('dt', '29/Oct/2005'),\n",
        "   ('ex', 'Kaakauko ira toupareveira aue-ia niugini stemp.'),\n",
        "   ('xp', 'Kaakauko em insect em i istap long niugini.'),\n",
        "   ('xe', 'The gray weevil is found on the PNG stamp.'),\n",
        "   ('ex', 'Kaakauko iria toupaeveira niugini stamia.'),\n",
        "   ('xp', 'Weevil i stap long niguini stamp.'),\n",
        "   ('xe', 'The gray weevil is on the New Guinea stamp.'),\n",
        "   ('ex',\n",
        "    'Kaakauko korekare iava oira iria iava varaua vurivurivira ora kaapovira toupaiveira.'),\n",
        "   ('xp',\n",
        "    'Kaakavuko em i wanpela kain binatang skin bilong em i braun na wait.'),\n",
        "   ('xe', 'Kaakavuko is an insect whose body is brown and white.')])]"
       ]
      }
     ],
     "prompt_number": 154
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 2.5 WordNet"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* semantic oriented dictionary of english. 155,287 words, and 117,659 synonym sets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import wordnet as wn"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 155
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.synsets('motorcar') # car.01 is the synset"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 156,
       "text": [
        "[Synset('car.n.01')]"
       ]
      }
     ],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.synset('car.n.01').lemma_names # each word of a synset can have several meanings"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 157,
       "text": [
        "['car', 'auto', 'automobile', 'machine', 'motorcar']"
       ]
      }
     ],
     "prompt_number": 157
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.synset('car.n.01').definition"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 158,
       "text": [
        "'a motor vehicle with four wheels; usually propelled by an internal combustion engine'"
       ]
      }
     ],
     "prompt_number": 158
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.synset('car.n.01').lemmas"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 159,
       "text": [
        "[Lemma('car.n.01.car'),\n",
        " Lemma('car.n.01.auto'),\n",
        " Lemma('car.n.01.automobile'),\n",
        " Lemma('car.n.01.machine'),\n",
        " Lemma('car.n.01.motorcar')]"
       ]
      }
     ],
     "prompt_number": 159
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.lemma('car.n.01.car')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 160,
       "text": [
        "Lemma('car.n.01.car')"
       ]
      }
     ],
     "prompt_number": 160
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.lemma('car.n.01.car').synset"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 161,
       "text": [
        "Synset('car.n.01')"
       ]
      }
     ],
     "prompt_number": 161
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.lemma('car.n.01.car').name"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 162,
       "text": [
        "'car'"
       ]
      }
     ],
     "prompt_number": 162
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.synsets('car')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 163,
       "text": [
        "[Synset('car.n.01'),\n",
        " Synset('car.n.02'),\n",
        " Synset('car.n.03'),\n",
        " Synset('car.n.04'),\n",
        " Synset('cable_car.n.01')]"
       ]
      }
     ],
     "prompt_number": 163
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for synset in wn.synsets('car'):\n",
      "    print synset.lemma_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['car', 'auto', 'automobile', 'machine', 'motorcar']\n",
        "['car', 'railcar', 'railway_car', 'railroad_car']\n",
        "['car', 'gondola']\n",
        "['car', 'elevator_car']\n",
        "['cable_car', 'car']\n"
       ]
      }
     ],
     "prompt_number": 164
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.lemmas('car')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 165,
       "text": [
        "[Lemma('car.n.01.car'),\n",
        " Lemma('car.n.02.car'),\n",
        " Lemma('car.n.03.car'),\n",
        " Lemma('car.n.04.car'),\n",
        " Lemma('cable_car.n.01.car')]"
       ]
      }
     ],
     "prompt_number": 165
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# DISH"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 166
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.synsets('dish') "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 167,
       "text": [
        "[Synset('dish.n.01'),\n",
        " Synset('dish.n.02'),\n",
        " Synset('dish.n.03'),\n",
        " Synset('smasher.n.02'),\n",
        " Synset('dish.n.05'),\n",
        " Synset('cup_of_tea.n.01'),\n",
        " Synset('serve.v.06'),\n",
        " Synset('dish.v.02')]"
       ]
      }
     ],
     "prompt_number": 167
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.synset('dish.n.01').lemma_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 168,
       "text": [
        "['dish']"
       ]
      }
     ],
     "prompt_number": 168
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.synset('dish.n.02').lemma_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 169,
       "text": [
        "['dish']"
       ]
      }
     ],
     "prompt_number": 169
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.synset('dish.n.01').definition"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 170,
       "text": [
        "'a piece of dishware normally used as a container for holding or serving food'"
       ]
      }
     ],
     "prompt_number": 170
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.synset('dish.n.02').definition"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 171,
       "text": [
        "'a particular item of prepared food'"
       ]
      }
     ],
     "prompt_number": 171
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.synset('dish.n.01').lemmas"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 172,
       "text": [
        "[Lemma('dish.n.01.dish')]"
       ]
      }
     ],
     "prompt_number": 172
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.synset('dish.n.02').lemmas"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 173,
       "text": [
        "[Lemma('dish.n.02.dish')]"
       ]
      }
     ],
     "prompt_number": 173
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.lemma('dish.n.01.dish')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 174,
       "text": [
        "Lemma('dish.n.01.dish')"
       ]
      }
     ],
     "prompt_number": 174
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.lemma('dish.n.02.dish')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 175,
       "text": [
        "Lemma('dish.n.02.dish')"
       ]
      }
     ],
     "prompt_number": 175
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.lemma('dish.n.01.dish').name"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 177,
       "text": [
        "'dish'"
       ]
      }
     ],
     "prompt_number": 177
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.lemma('dish.n.01.dish').synset"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 178,
       "text": [
        "Synset('dish.n.01')"
       ]
      }
     ],
     "prompt_number": 178
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for synset in wn.synsets('dish'):\n",
      "    print synset.lemma_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['dish']\n",
        "['dish']\n",
        "['dish', 'dishful']\n",
        "['smasher', 'stunner', 'knockout', 'beauty', 'ravisher', 'sweetheart', 'peach', 'lulu', 'looker', 'mantrap', 'dish']\n",
        "['dish', 'dish_aerial', 'dish_antenna', 'saucer']\n",
        "['cup_of_tea', 'bag', 'dish']\n",
        "['serve', 'serve_up', 'dish_out', 'dish_up', 'dish']\n",
        "['dish']\n"
       ]
      }
     ],
     "prompt_number": 179
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.lemmas('dish')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 180,
       "text": [
        "[Lemma('dish.n.01.dish'),\n",
        " Lemma('dish.n.02.dish'),\n",
        " Lemma('dish.n.03.dish'),\n",
        " Lemma('smasher.n.02.dish'),\n",
        " Lemma('dish.n.05.dish'),\n",
        " Lemma('cup_of_tea.n.01.dish'),\n",
        " Lemma('serve.v.06.dish'),\n",
        " Lemma('dish.v.02.dish')]"
       ]
      }
     ],
     "prompt_number": 180
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## The WordNet Hierachy"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "motorcar = wn.synset('car.n.01')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 182
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "types_of_motorcars = motorcar.hyponyms() # motorcar acts like parent -> entity state. These are unique beginners or root synsets"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 183
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "types_of_motorcars[26]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 184,
       "text": [
        "Synset('ambulance.n.01')"
       ]
      }
     ],
     "prompt_number": 184
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sorted([lemma.name for synset in types_of_motorcars for lemma in synset.lemmas])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 185,
       "text": [
        "['Model_T',\n",
        " 'S.U.V.',\n",
        " 'SUV',\n",
        " 'Stanley_Steamer',\n",
        " 'ambulance',\n",
        " 'beach_waggon',\n",
        " 'beach_wagon',\n",
        " 'bus',\n",
        " 'cab',\n",
        " 'compact',\n",
        " 'compact_car',\n",
        " 'convertible',\n",
        " 'coupe',\n",
        " 'cruiser',\n",
        " 'electric',\n",
        " 'electric_automobile',\n",
        " 'electric_car',\n",
        " 'estate_car',\n",
        " 'gas_guzzler',\n",
        " 'hack',\n",
        " 'hardtop',\n",
        " 'hatchback',\n",
        " 'heap',\n",
        " 'horseless_carriage',\n",
        " 'hot-rod',\n",
        " 'hot_rod',\n",
        " 'jalopy',\n",
        " 'jeep',\n",
        " 'landrover',\n",
        " 'limo',\n",
        " 'limousine',\n",
        " 'loaner',\n",
        " 'minicar',\n",
        " 'minivan',\n",
        " 'pace_car',\n",
        " 'patrol_car',\n",
        " 'phaeton',\n",
        " 'police_car',\n",
        " 'police_cruiser',\n",
        " 'prowl_car',\n",
        " 'race_car',\n",
        " 'racer',\n",
        " 'racing_car',\n",
        " 'roadster',\n",
        " 'runabout',\n",
        " 'saloon',\n",
        " 'secondhand_car',\n",
        " 'sedan',\n",
        " 'sport_car',\n",
        " 'sport_utility',\n",
        " 'sport_utility_vehicle',\n",
        " 'sports_car',\n",
        " 'squad_car',\n",
        " 'station_waggon',\n",
        " 'station_wagon',\n",
        " 'stock_car',\n",
        " 'subcompact',\n",
        " 'subcompact_car',\n",
        " 'taxi',\n",
        " 'taxicab',\n",
        " 'tourer',\n",
        " 'touring_car',\n",
        " 'two-seater',\n",
        " 'used-car',\n",
        " 'waggon',\n",
        " 'wagon']"
       ]
      }
     ],
     "prompt_number": 185
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "motorcar.hypernyms()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 151,
       "text": [
        "[Synset('motor_vehicle.n.01')]"
       ]
      }
     ],
     "prompt_number": 151
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "paths = motorcar.hypernym_paths() # navigates up paths"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 152
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(paths)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 153,
       "text": [
        "2"
       ]
      }
     ],
     "prompt_number": 153
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[synset.name for synset in paths[0]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 154,
       "text": [
        "['entity.n.01',\n",
        " 'physical_entity.n.01',\n",
        " 'object.n.01',\n",
        " 'whole.n.02',\n",
        " 'artifact.n.01',\n",
        " 'instrumentality.n.03',\n",
        " 'container.n.01',\n",
        " 'wheeled_vehicle.n.01',\n",
        " 'self-propelled_vehicle.n.01',\n",
        " 'motor_vehicle.n.01',\n",
        " 'car.n.01']"
       ]
      }
     ],
     "prompt_number": 154
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[synset.name for synset in paths[1]] # shows we have 2 paths between 'entity.n.01' and 'car.n.01'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 157,
       "text": [
        "['entity.n.01',\n",
        " 'physical_entity.n.01',\n",
        " 'object.n.01',\n",
        " 'whole.n.02',\n",
        " 'artifact.n.01',\n",
        " 'instrumentality.n.03',\n",
        " 'conveyance.n.03',\n",
        " 'vehicle.n.01',\n",
        " 'wheeled_vehicle.n.01',\n",
        " 'self-propelled_vehicle.n.01',\n",
        " 'motor_vehicle.n.01',\n",
        " 'car.n.01']"
       ]
      }
     ],
     "prompt_number": 157
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "motorcar.root_hypernyms()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 158,
       "text": [
        "[Synset('entity.n.01')]"
       ]
      }
     ],
     "prompt_number": 158
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# More lexical relations - lexical relations are hypernyms and holoymns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 161
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# another way to Navigate is from Items -> components (Meronyms) or the things they are contained in Holonyms"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 162
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.synset('tree.n.01').part_meronyms()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 163,
       "text": [
        "[Synset('burl.n.02'),\n",
        " Synset('crown.n.07'),\n",
        " Synset('stump.n.01'),\n",
        " Synset('trunk.n.01'),\n",
        " Synset('limb.n.02')]"
       ]
      }
     ],
     "prompt_number": 163
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.synset('tree.n.01').substance_meronyms()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 164,
       "text": [
        "[Synset('heartwood.n.01'), Synset('sapwood.n.01')]"
       ]
      }
     ],
     "prompt_number": 164
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.synset('tree.n.01').member_holonyms()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 166,
       "text": [
        "[Synset('forest.n.01')]"
       ]
      }
     ],
     "prompt_number": 166
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for synset in wn.synsets('mint', wn.NOUN):\n",
      "    print synset.name + ':', synset.definition"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "batch.n.02: (often followed by `of') a large number or amount or extent\n",
        "mint.n.02: any north temperate plant of the genus Mentha with aromatic leaves and small mauve flowers\n",
        "mint.n.03: any member of the mint family of plants\n",
        "mint.n.04: the leaves of a mint plant used fresh or candied\n",
        "mint.n.05: a candy that is flavored with a mint oil\n",
        "mint.n.06: a plant where money is coined by authority of the government\n"
       ]
      }
     ],
     "prompt_number": 167
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.synset('mint.n.04').part_holonyms()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 169,
       "text": [
        "[Synset('mint.n.02')]"
       ]
      }
     ],
     "prompt_number": 169
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.synset('mint.n.04').substance_holonyms()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 170,
       "text": [
        "[Synset('mint.n.05')]"
       ]
      }
     ],
     "prompt_number": 170
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.synset('walk.v.01').entailments() # walking entails stepping - act of walking involves act of stepping"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 172,
       "text": [
        "[Synset('step.v.01')]"
       ]
      }
     ],
     "prompt_number": 172
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.synset('eat.v.01').entailments() # act of eating entails swallowing"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 173,
       "text": [
        "[Synset('swallow.v.01'), Synset('chew.v.01')]"
       ]
      }
     ],
     "prompt_number": 173
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.synset('tease.v.03').entailments()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 174,
       "text": [
        "[Synset('arouse.v.07'), Synset('disappoint.v.01')]"
       ]
      }
     ],
     "prompt_number": 174
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.lemma('supply.n.02.supply').antonyms() # shows lexical relationships happen between lemmas"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 176,
       "text": [
        "[Lemma('demand.n.02.demand')]"
       ]
      }
     ],
     "prompt_number": 176
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.lemma('rush.v.01.rush').antonyms()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 178,
       "text": [
        "[Lemma('linger.v.04.linger')]"
       ]
      }
     ],
     "prompt_number": 178
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.lemma('horizontal.a.01.horizontal').antonyms()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 180,
       "text": [
        "[Lemma('vertical.a.01.vertical'), Lemma('inclined.a.02.inclined')]"
       ]
      }
     ],
     "prompt_number": 180
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.lemma('legato.r.01.legato').antonyms()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 181,
       "text": [
        "[Lemma('staccato.r.01.staccato')]"
       ]
      }
     ],
     "prompt_number": 181
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Semantic similarity\n",
      "# If 2 synsets share a very specific hypernym one that is low down in hypernym then they must be related"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 182
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "right = wn.synset('right_whale.n.01')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 184
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "orca = wn.synset('orca.n.01')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 186
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "minke = wn.synset('minke_whale.n.01')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 188
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tortoise = wn.synset('tortoise.n.01')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 189
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "novel = wn.synset('novel.n.01')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "right.lowest_common_hypernyms(minke)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 191,
       "text": [
        "[Synset('baleen_whale.n.01')]"
       ]
      }
     ],
     "prompt_number": 191
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "right.lowest_common_hypernyms(orca) # very specific"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 192,
       "text": [
        "[Synset('whale.n.02')]"
       ]
      }
     ],
     "prompt_number": 192
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "right.lowest_common_hypernyms(tortoise)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 193,
       "text": [
        "[Synset('vertebrate.n.01')]"
       ]
      }
     ],
     "prompt_number": 193
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "right.lowest_common_hypernyms(novel) #completely general"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 194,
       "text": [
        "[Synset('entity.n.01')]"
       ]
      }
     ],
     "prompt_number": 194
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.synset('baleen_whale.n.01').min_depth() # By looking at depth we can quantify this concept"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 195,
       "text": [
        "14"
       ]
      }
     ],
     "prompt_number": 195
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.synset('whale.n.02').min_depth()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 196,
       "text": [
        "13"
       ]
      }
     ],
     "prompt_number": 196
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.synset('vertebrate.n.01').min_depth()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 198,
       "text": [
        "8"
       ]
      }
     ],
     "prompt_number": 198
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.synset('entity.n.01').min_depth()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 199,
       "text": [
        "0"
       ]
      }
     ],
     "prompt_number": 199
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "right.path_similarity(minke) # path similarity defines a score in 0-1 based on shortest path that connects concepts in the "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 201,
       "text": [
        "0.25"
       ]
      }
     ],
     "prompt_number": 201
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "right.path_similarity(orca)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 202,
       "text": [
        "0.16666666666666666"
       ]
      }
     ],
     "prompt_number": 202
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "right.path_similarity(tortoise)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 203,
       "text": [
        "0.07692307692307693"
       ]
      }
     ],
     "prompt_number": 203
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ri"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}