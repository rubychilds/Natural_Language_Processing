{
 "metadata": {
  "name": "",
  "signature": "sha256:a6b71a8ba368092437accf06dbd29594189ae0673ac3f67d20101822e29b613e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk, re, pprint\n",
      "from urllib import urlopen"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "url = url = \"http://www.gutenberg.org/files/2554/2554.txt\"\n",
      "raw = urlopen(url).read()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(raw)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "str"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(raw)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "1176893"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "raw[:75]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "'The Project Gutenberg EBook of Crime and Punishment, by Fyodor Dostoevsky\\r\\n'"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokens = nltk.word_tokenize(raw) # turns the raw text to tokens - list in order to sort etc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(tokens)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "list"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokens[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "['The',\n",
        " 'Project',\n",
        " 'Gutenberg',\n",
        " 'EBook',\n",
        " 'of',\n",
        " 'Crime',\n",
        " 'and',\n",
        " 'Punishment',\n",
        " ',',\n",
        " 'by']"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text = nltk.Text(tokens) #converts into nltk.text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "nltk.text.Text"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text[10:20]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "['Fyodor',\n",
        " 'Dostoevsky',\n",
        " 'This',\n",
        " 'eBook',\n",
        " 'is',\n",
        " 'for',\n",
        " 'the',\n",
        " 'use',\n",
        " 'of',\n",
        " 'anyone']"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text.collocations() # Collocations are expressions of multiple words which commonly co-occur\n",
      "# Project Gutenberg appears as a collocation. This is because each text downloaded from Project Gutenberg contains a \n",
      "# header with the name of the text, the author, the names of people who scanned and corrected the text, a license,"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Building collocations list\n",
        "Katerina Ivanovna; Pyotr Petrovitch; Pulcheria Alexandrovna; Avdotya\n",
        "Romanovna; Marfa Petrovna; Rodion Romanovitch; Sofya Semyonovna; old\n",
        "woman; Project Gutenberg-tm; Porfiry Petrovitch; Amalia Ivanovna;\n",
        "great deal; Project Gutenberg; Andrey Semyonovitch; Nikodim Fomitch;\n",
        "young man; Dmitri Prokofitch; n't know; Ilya Petrovitch; Good heavens"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# cant detect content start/end -> use find:\n",
      "raw.find(\"PART I\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "5338"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "raw.rfind(\"End of Project Gutenberg's Crime\") # rfind is a reverse find (quicker of you expect to be at the end)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "1157743"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# select inbetween\n",
      "raw = raw[5338:1157743]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "raw.find(\"PART I\") #test we cannot find anything else the same as the starting remark"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "0"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# DEALING WITH HTML"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "url = 'http://news.bbc.co.uk/2/hi/health/2284783.stm'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "html = urlopen(url).read()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "html[:60]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "'<!doctype html public \"-//W3C//DTD HTML 4.0 Transitional//EN'"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "raw = nltk.clean_html(html) # can use BeautifulSoup's get_text() "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "raw[:60]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "\"BBC NEWS | Health | Blondes 'to die out in 200 years' \\r\\n \\r\\n \""
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokens = nltk.word_tokenize(raw)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text = nltk.Text(tokens) # converts back to text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text.concordance('gene')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Building index...\n",
        "Displaying 5 of 5 matches:\n",
        "hey say too few people now carry the gene for blondes to last beyond the next \n",
        " have blonde hair , it must have the gene on both sides of the family in the g\n",
        "ere is a disadvantage of having that gene or by chance. They do n't disappear \n",
        "des would disappear is if having the gene was a disadvantage and I do not thin\n",
        "s ' Vegetables ward off Alzheimer 's Gene defect explains high blood pressure \n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Processing RSS Feeds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = open('document.txt') # choose a local file"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IOError",
       "evalue": "[Errno 2] No such file or directory: 'document.txt'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-29-58e319b630ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'document.txt'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# choose a local file\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'document.txt'"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "os.listdir('.') # lists all in that dir"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "['.git',\n",
        " '.gitignore',\n",
        " '.ipynb_checkpoints',\n",
        " 'ch1-exercises.ipynb',\n",
        " 'ch1.ipynb',\n",
        " 'ch2-exercises.ipynb',\n",
        " 'ch2.ipynb',\n",
        " 'ch3.ipynb',\n",
        " 'Intro to NLTK - TheLadders.ipynb',\n",
        " 'Lightening Talk.ipynb',\n",
        " 'README.md']"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXTRACT TEXT FROM PDF, MSWORD, OTHER"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = raw_input('enter text\u2026 ')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# NLP Pipeline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "raw = open('').read()\n",
      "type(raw)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 3.2. STRINGS - TEXT PROCESSING AT THE LOWEST LEVEL"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "monty = 'Monty Python'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# All quite zzzzz.... about strings ...."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 3.3. TEXT PROCESSING WITH UNICODE"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path = nltk.data.find('corpora/unicode_samples/polish-lat2.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import codecs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = codecs.open(path, encoding='latin2')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for line in f:\n",
      "        line = line.strip()\n",
      "        print line.encode('unicode_escape')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ord('a')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = u'\\u0061'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nacute = u'\\u0144'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nacute"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nacute_utf = nacute.encode('utf')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print repr(nacute_utf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import unicodedata"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lines = codecs.open(path, encoding='latin2').readlines()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "line = lines[2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print line.encode('unicode_escape')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for c in line:\n",
      "    if ord(c) > 127:\n",
      "        print '%r U+%04x %s' % (c.encode('utf8'), ord(c), unicodedata.name(c))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "line.find(u'zosta\\u0142y')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "line = line.lower()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print line.encode('unicode_escape')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m = re.search(u'\\u015b\\w*',line)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m.group()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.word_tokenize(line)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 3.4 REGULAR EXPERSSIONS FOR DETECTING WORD PATTERNS"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wordlist = [w for w in nltk.corpus.words.words('en') if w.islower()]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ed_words = [w for w in wordlist if re.search('ed$', w)] # end of line character"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print ed_words[1:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['abandoned', 'abased', 'abashed', 'abatised', 'abed', 'aborted', 'abridged', 'abscessed', 'absconded']\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "words = [w for w in wordlist if re.search('^..j..t..$', w)]  # use of dots for undefined characters. one dot per char"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print words[1:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['adjuster', 'dejected', 'dejectly', 'injector', 'majestic', 'objectee', 'objector', 'rejecter', 'rejector']\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print [w for w in wordlist if re.search('^..j..t..', w)][:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['abjectedness', 'abjection', 'abjective', 'abjectly', 'abjectness', 'adjection', 'adjectional', 'adjectival', 'adjectivally', 'adjective']\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[w for w in wordlist if re.search('^[ghi][mno][jlk][def]$',w)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 66,
       "text": [
        "['gold', 'golf', 'hold', 'hole']"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chat_words = sorted(set(w for w in nltk.corpus.nps_chat.words()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[w for w in chat_words if re.search('^m+i+n+e+$', w)] "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 69,
       "text": [
        "['miiiiiiiiiiiiinnnnnnnnnnneeeeeeeeee',\n",
        " 'miiiiiinnnnnnnnnneeeeeeee',\n",
        " 'mine',\n",
        " 'mmmmmmmmiiiiiiiiinnnnnnnnneeeeeeee']"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[w for w in wordlist if re.search('^[ha]+$', w)] # use + means zero of more instances of preceeding item"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 72,
       "text": [
        "['a', 'aa', 'ah', 'aha', 'h', 'ha', 'hah']"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[w for w in wordlist if re.search('^[ha]+$', w)] # use + means one of more instances of preceeding item"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 72,
       "text": [
        "['a', 'aa', 'ah', 'aha', 'h', 'ha', 'hah']"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[w for w in chat_words if re.search('^[^aieouAEIOU]+$', w)][400:410] # Should exclude all vowels"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "[\"@..3-,'~.\", 'B', 'C', 'CDT', 'CST', 'CT', 'Cry', 'Ct', 'Ctrl', 'D']"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[w for w in chat_words if re.search('^m*i*n*e*$', w)] # * zero or more. *+ are Kleene closures"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 75,
       "text": [
        "['',\n",
        " 'e',\n",
        " 'i',\n",
        " 'in',\n",
        " 'm',\n",
        " 'me',\n",
        " 'meeeeeeeeeeeee',\n",
        " 'mi',\n",
        " 'miiiiiiiiiiiiinnnnnnnnnnneeeeeeeeee',\n",
        " 'miiiiiinnnnnnnnnneeeeeeee',\n",
        " 'min',\n",
        " 'mine',\n",
        " 'mm',\n",
        " 'mmm',\n",
        " 'mmmm',\n",
        " 'mmmmm',\n",
        " 'mmmmmm',\n",
        " 'mmmmmmmmiiiiiiiiinnnnnnnnneeeeeeee',\n",
        " 'mmmmmmmmmm',\n",
        " 'mmmmmmmmmmmmm',\n",
        " 'mmmmmmmmmmmmmm',\n",
        " 'n',\n",
        " 'ne']"
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wsj = sorted(set(nltk.corpus.treebank.words()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wsj[1:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "['#', '$', '%', '&', \"'\", \"''\", \"'30s\", \"'40s\", \"'50s\"]"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[w for w in wsj if re.search('^[0-9]+\\.[0-9]+$',w)][:10] # decimal numbers"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "['0.0085', '0.05', '0.1', '0.16', '0.2', '0.25', '0.28', '0.3', '0.4', '0.5']"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[w for w in wsj if re.search('^[A-Z]+\\$$',w)] #escaping $"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "['C$', 'US$']"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[w for w in wsj if re.search('^[0-9]{4}$',w)][:10] # for all years, repeat number 0-9"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "['1614',\n",
        " '1637',\n",
        " '1787',\n",
        " '1901',\n",
        " '1903',\n",
        " '1917',\n",
        " '1925',\n",
        " '1929',\n",
        " '1933',\n",
        " '1934']"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[w for w in wsj if re.search('^[0-9]+-[a-z]{3,5}',w)][1:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "['10-lap',\n",
        " '10-year',\n",
        " '100-megabyte',\n",
        " '100-share',\n",
        " '11-month-old',\n",
        " '12-member',\n",
        " '12-point',\n",
        " '12-year',\n",
        " '14-hour']"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[w for w in wsj if re.search('^[a-z]{5,}-[a-z]{2,3}-[a-z]{3,6}',w)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 42,
       "text": [
        "['black-and-white',\n",
        " 'bread-and-butter',\n",
        " 'father-in-law',\n",
        " 'machine-gun-toting',\n",
        " 'savings-and-loan',\n",
        " 'search-and-seizure',\n",
        " 'truth-in-lending']"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[w for w in wsj if re.search('(ed|ing)$',w)][:10] # end must be a ed or ing"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "['62%-owned',\n",
        " 'Absorbed',\n",
        " 'According',\n",
        " 'Adopting',\n",
        " 'Advanced',\n",
        " 'Advancing',\n",
        " 'Alfred',\n",
        " 'Allied',\n",
        " 'Annualized',\n",
        " 'Anything']"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#.\tWildcard, matches any character\n",
      "#^abc\tMatches some pattern abc at the start of a string\n",
      "#abc$\tMatches some pattern abc at the end of a string\n",
      "#[abc]\tMatches one of a set of characters\n",
      "#[A-Z0-9]\tMatches one of a range of characters\n",
      "#ed|ing|s\tMatches one of the specified strings (disjunction)\n",
      "#*\tZero or more of previous item, e.g. a*, [a-z]* (also known as Kleene Closure)\n",
      "#+\tOne or more of previous item, e.g. a+, [a-z]+\n",
      "#?\tZero or one of the previous item (i.e. optional), e.g. a?, [a-z]?\n",
      "#{n}\tExactly n repeats where n is a non-negative integer\n",
      "#{n,}\tAt least n repeats\n",
      "#{,n}\tNo more than n repeats\n",
      "#{m,n}\tAt least m and no more than n repeats\n",
      "#a(b|c)+\tParentheses that indicate the scope of the operators"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#3.5 USEFUL APPLICATIONS OF REGULAR EXPRESSIONS"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word = 'supercalifragilisticexpialidocious'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "re.findall(r'[aeiou]',word)[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 50,
       "text": [
        "['u', 'e', 'a', 'i', 'a']"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(re.findall(r'[aeiou]',word))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "16"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wsj = sorted(set(nltk.corpus.treebank.words()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fd = nltk.FreqDist(vs for word in wsj for vs in re.findall(r'[aeiou]{2}',word))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print fd.items()[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('io', 577), ('ea', 486), ('ou', 335), ('ie', 334), ('ai', 264), ('ia', 256), ('ee', 220), ('oo', 175), ('ue', 110), ('ua', 109)]\n"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[int(n) for n in re.findall(r'[0-9]+', '2009-12-31')]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 58,
       "text": [
        "[2009, 12, 31]"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "regexp = r'^[AEIOUaeiou]+|[AEIOUaeiou]+$|[^AEIOUaeiou]'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compress(word):\n",
      "    pieces = re.findall(regexp,word)\n",
      "    return ''.join(pieces)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "english_udhr = nltk.corpus.udhr.words('English-Latin1')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print nltk.tokenwrap(compress(w) for w in english_udhr[:75])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Unvrsl Dclrtn of Hmn Rghts Prmble Whrs rcgntn of the inhrnt dgnty and\n",
        "of the eql and inlnble rghts of all mmbrs of the hmn fmly is the fndtn\n",
        "of frdm , jstce and pce in the wrld , Whrs dsrgrd and cntmpt fr hmn\n",
        "rghts hve rsltd in brbrs acts whch hve outrgd the cnscnce of mnknd ,\n",
        "and the advnt of a wrld in whch hmn bngs shll enjy frdm of spch and\n"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rotokas_words = nltk.corpus.toolbox.words('rotokas.dic')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cvs = [cv for w in rotokas_words for cv in re.findall(r'[ptksvr][aeious]',w)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfd = nltk.ConditionalFreqDist(cvs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfd.tabulate()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "     a    e    i    o    u\n",
        "k  418  148   94  420  173\n",
        "p   83   31  105   34   51\n",
        "r  187   63   84   89   79\n",
        "s    0    0  100    2    1\n",
        "t   47    8    0  148   37\n",
        "v   93   27  105   48   49\n"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv_word_pairds = [(cv,w) for w in rotokas_words for cv in re.findall(r'[ptksvr][aeioou]',w)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv_index = nltk.Index(cv_word_pairds) # conversion into index to get all words containing pairs of letters quickly"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv_index['su']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 83,
       "text": [
        "['kasuari']"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv_index['po'][:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 85,
       "text": [
        "['kaapo',\n",
        " 'kaapopato',\n",
        " 'kaipori',\n",
        " 'kaiporipie',\n",
        " 'kaiporivira',\n",
        " 'kapo',\n",
        " 'kapoa',\n",
        " 'kapokao',\n",
        " 'kapokapo',\n",
        " 'kapokapo']"
       ]
      }
     ],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Finding word stems"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def stem(word):\n",
      "    for suffix in ['ing','ed','ly','ies','ious','es','s','ment']:\n",
      "        if word.endswith(suffix):\n",
      "            return word[:len(suffix)]\n",
      "    return word"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "re.findall(r'^.*(ing|ly|ies|ious|ies|es|s|ment)$','processing') # returns the matched part - () select substrings to be extracted"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 88,
       "text": [
        "['ing']"
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "re.findall(r'^.*(?:ing|ly|ies|ious|ies|es|s|ment)$','processing') # use ?: to return the part before matched"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 89,
       "text": [
        "['processing']"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "re.findall(r'^(.*)(?:ing|ly|ies|ious|ies|es|s|ment)$','processing') # returns word before but not matched part"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 90,
       "text": [
        "['process']"
       ]
      }
     ],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "re.findall(r'^(.*)(ing|ly|ies|ious|ies|es|s|ment)$','processing')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 91,
       "text": [
        "[('process', 'ing')]"
       ]
      }
     ],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "re.findall(r'^(.*)(ing|ly|ies|ious|ies|es|s|ment)$','processes') # greedy - continues to end of match"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 92,
       "text": [
        "[('processe', 's')]"
       ]
      }
     ],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "re.findall(r'^(.*?)(ing|ly|ies|ious|ies|es|s|ment)?$','ruby') # there may not be any matches"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 98,
       "text": [
        "[('ruby', '')]"
       ]
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def stemword(word):\n",
      "    stem, suffix = re.findall(r'^(.*?)(ious|ment|ing|es|s|ly|ed|ive)?$', word)[0]\n",
      "    return stem"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "raw = \"\"\"DENNIS: Listen, strange women lying in ponds distributing swords\n",
      "... is no basis for a system of government.  Supreme executive power derives from\n",
      "... a mandate from the masses, not from some farcical aquatic ceremony.\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokens = nltk.word_tokenize(raw)\n",
      "print tokens"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['DENNIS', ':', 'Listen', ',', 'strange', 'women', 'lying', 'in', 'ponds', 'distributing', 'swords', 'is', 'no', 'basis', 'for', 'a', 'system', 'of', 'government.', 'Supreme', 'executive', 'power', 'derives', 'from', 'a', 'mandate', 'from', 'the', 'masses', ',', 'not', 'from', 'some', 'farcical', 'aquatic', 'ceremony', '.']\n"
       ]
      }
     ],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[stem(t) for t in tokens][:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 110,
       "text": [
        "['DENNIS', ':', 'Listen', ',', 'strange', 'women', 'lyi', 'in', 'p', 'dis']"
       ]
      }
     ],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Seaching tokenized text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import gutenberg, nps_chat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "moby = nltk.Text(gutenberg.words('melville-moby_dick.txt'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "moby.findall(r'<a> (<.*>) <man>') #<word_boundaries>, (<.*>) to match and return any word inbetween a --- man "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "monied; nervous; dangerous; white; white; white; pious; queer; good;\n",
        "mature; white; Cape; great; wise; wise; butterless; white; fiendish;\n",
        "pale; furious; better; certain; complete; dismasted; younger; brave;\n",
        "brave; brave; brave\n"
       ]
      }
     ],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chat = nltk.Text(nps_chat.words())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chat.findall(r'<.*> <.*> <bro>')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "you rule bro; telling you bro; u twizted bro\n"
       ]
      }
     ],
     "prompt_number": 116
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chat.findall(r'<l.*>{3,}')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "lol lol lol; lmao lol lol; lol lol lol; la la la la la; la la la; la\n",
        "la la; lovely lol lol love; lol lol lol.; la la la; la la la\n"
       ]
      }
     ],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.re_show(r'^[a-z]{3,5}',raw)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DENNIS: Listen, strange women lying in ponds distributing swords\n",
        "is no basis for a system of government.  Supreme executive power derives from\n",
        "a mandate from the masses, not from some farcical aquatic ceremony.\n"
       ]
      }
     ],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.re_show(r'^[A-Z]{3,6}',raw)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{DENNIS}: Listen, strange women lying in ponds distributing swords\n",
        "is no basis for a system of government.  Supreme executive power derives from\n",
        "a mandate from the masses, not from some farcical aquatic ceremony.\n"
       ]
      }
     ],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import brown"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 129
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hobbies_learned = nltk.Text(brown.words(categories=['hobbies','learned']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 131
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hobbies_learned.findall(r'<\\w*> <and> <other> <\\w*s>')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "speed and other activities; water and other liquids; tomb and other\n",
        "landmarks; Statues and other monuments; pearls and other jewels;\n",
        "charts and other items; roads and other features; figures and other\n",
        "objects; military and other areas; demands and other factors;\n",
        "abstracts and other compilations; iron and other metals\n"
       ]
      }
     ],
     "prompt_number": 133
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 3.6 Normalizing Text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 134
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokens[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 136,
       "text": [
        "['DENNIS',\n",
        " ':',\n",
        " 'Listen',\n",
        " ',',\n",
        " 'strange',\n",
        " 'women',\n",
        " 'lying',\n",
        " 'in',\n",
        " 'ponds',\n",
        " 'distributing']"
       ]
      }
     ],
     "prompt_number": 136
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "porter = nltk.PorterStemmer()\n",
      "lancaster = nltk.LancasterStemmer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 137
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print [porter.stem(w) for w in tokens ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['DENNI', ':', 'Listen', ',', 'strang', 'women', 'lie', 'in', 'pond', 'distribut', 'sword', 'is', 'no', 'basi', 'for', 'a', 'system', 'of', 'government.', 'Suprem', 'execut', 'power', 'deriv', 'from', 'a', 'mandat', 'from', 'the', 'mass', ',', 'not', 'from', 'some', 'farcic', 'aquat', 'ceremoni', '.']\n"
       ]
      }
     ],
     "prompt_number": 139
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print [lancaster.stem(w) for w in tokens]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['den', ':', 'list', ',', 'strange', 'wom', 'lying', 'in', 'pond', 'distribut', 'sword', 'is', 'no', 'bas', 'for', 'a', 'system', 'of', 'government.', 'suprem', 'execut', 'pow', 'der', 'from', 'a', 'mand', 'from', 'the', 'mass', ',', 'not', 'from', 'som', 'farc', 'aqu', 'ceremony', '.']\n"
       ]
      }
     ],
     "prompt_number": 141
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grail = nltk.corpus.webtext.words('grail.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 143
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class IndexedText(object):\n",
      "    def __init__(self, stemmer, text):\n",
      "        self._text = text\n",
      "        self._stemmer = stemmer\n",
      "        self._index = nltk.Index((self._stem(word), i)\n",
      "                                 for (i, word) in enumerate(text))\n",
      "\n",
      "    def concordance(self, word, width=40):\n",
      "        key = self._stem(word)\n",
      "        wc = width/4                # words of context\n",
      "        for i in self._index[key]:\n",
      "            lcontext = ' '.join(self._text[i-wc:i])\n",
      "            rcontext = ' '.join(self._text[i:i+wc])\n",
      "            ldisplay = '%*s'  % (width, lcontext[-width:])\n",
      "            rdisplay = '%-*s' % (width, rcontext[:width])\n",
      "            print ldisplay, rdisplay\n",
      "\n",
      "    def _stem(self, word):\n",
      "        return self._stemmer.stem(word).lower()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 147
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text = IndexedText(porter, grail)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 149
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text.concordance('lie')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "r king ! DENNIS : Listen , strange women lying in ponds distributing swords is no\n",
        " beat a very brave retreat . ROBIN : All lies ! MINSTREL : [ singing ] Bravest of\n",
        "       Nay . Nay . Come . Come . You may lie here . Oh , but you are wounded !   \n",
        "doctors immediately ! No , no , please ! Lie down . [ clap clap ] PIGLET : Well  \n",
        "ere is much danger , for beyond the cave lies the Gorge of Eternal Peril , which \n",
        "   you . Oh ... TIM : To the north there lies a cave -- the cave of Caerbannog --\n",
        "h it and lived ! Bones of full fifty men lie strewn about its lair . So , brave k\n",
        "not stop our fight ' til each one of you lies dead , and the Holy Grail returns t\n"
       ]
      }
     ],
     "prompt_number": 150
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Lemmatization"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 151
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wnl = nltk.WordNetLemmatizer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 152
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[wnl.lemmatize(t) for t in tokens][:10] # removed affixes if resulting word is in dictionary eg. women -> woman"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 154,
       "text": [
        "['DENNIS',\n",
        " ':',\n",
        " 'Listen',\n",
        " ',',\n",
        " 'strange',\n",
        " 'woman',\n",
        " 'lying',\n",
        " 'in',\n",
        " 'pond',\n",
        " 'distributing']"
       ]
      }
     ],
     "prompt_number": 154
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 3.7 Regular Expressions for Tokenizing Text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "raw = \"\"\"'When I'M a Duchess,' she said to herself, (not in a very hopeful tone\n",
      "... though), 'I won't have any pepper in my kitchen AT ALL. Soup does very\n",
      "... well without--Maybe it's always pepper that makes people hot-tempered,'...\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 155
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print re.split('[ \\t\\n]+',raw) # matches one or more space, tab, nl \n",
      "# r says to  treat string literally rather than process any backslashed characters"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[\"'When\", \"I'M\", 'a', \"Duchess,'\", 'she', 'said', 'to', 'herself,', '(not', 'in', 'a', 'very', 'hopeful', 'tone', 'though),', \"'I\", \"won't\", 'have', 'any', 'pepper', 'in', 'my', 'kitchen', 'AT', 'ALL.', 'Soup', 'does', 'very', 'well', 'without--Maybe', \"it's\", 'always', 'pepper', 'that', 'makes', 'people', \"hot-tempered,'...\"]\n"
       ]
      }
     ],
     "prompt_number": 165
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print re.split(r'\\W+',raw) #Splits on all that are not letters, digits, underscore"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['', 'When', 'I', 'M', 'a', 'Duchess', 'she', 'said', 'to', 'herself', 'not', 'in', 'a', 'very', 'hopeful', 'tone', 'though', 'I', 'won', 't', 'have', 'any', 'pepper', 'in', 'my', 'kitchen', 'AT', 'ALL', 'Soup', 'does', 'very', 'well', 'without', 'Maybe', 'it', 's', 'always', 'pepper', 'that', 'makes', 'people', 'hot', 'tempered', '']\n"
       ]
      }
     ],
     "prompt_number": 164
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print re.findall(r'\\w+|\\S\\w*',raw) # first tries to match any sequence of word char\n",
      "# \\S non whitespace character, complement of \\s"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[\"'When\", 'I', \"'M\", 'a', 'Duchess', ',', \"'\", 'she', 'said', 'to', 'herself', ',', '(not', 'in', 'a', 'very', 'hopeful', 'tone', 'though', ')', ',', \"'I\", 'won', \"'t\", 'have', 'any', 'pepper', 'in', 'my', 'kitchen', 'AT', 'ALL', '.', 'Soup', 'does', 'very', 'well', 'without', '-', '-Maybe', 'it', \"'s\", 'always', 'pepper', 'that', 'makes', 'people', 'hot', '-tempered', ',', \"'\", '.', '.', '.']\n"
       ]
      }
     ],
     "prompt_number": 163
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print re.findall(r\"\\w+(?:[-']\\w+)*|'|[-.(]+|\\S\\w*\", raw)\n",
      "#\\w+ follower by zero or more instance of [-']\\w+"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[\"'\", 'When', \"I'M\", 'a', 'Duchess', ',', \"'\", 'she', 'said', 'to', 'herself', ',', '(', 'not', 'in', 'a', 'very', 'hopeful', 'tone', 'though', ')', ',', \"'\", 'I', \"won't\", 'have', 'any', 'pepper', 'in', 'my', 'kitchen', 'AT', 'ALL', '.', 'Soup', 'does', 'very', 'well', 'without', '--', 'Maybe', \"it's\", 'always', 'pepper', 'that', 'makes', 'people', 'hot-tempered', ',', \"'\", '...']\n"
       ]
      }
     ],
     "prompt_number": 167
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\\b\tWord boundary (zero width)\n",
      "#\\d\tAny decimal digit (equivalent to [0-9])\n",
      "#\\D\tAny non-digit character (equivalent to [^0-9])\n",
      "#\\s\tAny whitespace character (equivalent to [ \\t\\n\\r\\f\\v]\n",
      "#\\S\tAny non-whitespace character (equivalent to [^ \\t\\n\\r\\f\\v])\n",
      "#\\w\tAny alphanumeric character (equivalent to [a-zA-Z0-9_])\n",
      "#\\W\tAny non-alphanumeric character (equivalent to [^a-zA-Z0-9_])\n",
      "#\\t\tThe tab character\n",
      "#\\n\tThe newline character"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text = 'That U.S.A. poster-print costs $19.00'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 177
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pattern = r'''(?x) # flag for verbose regexps\n",
      "    ([A-Z]\\.)+ # abbreviations\n",
      "    | \\w+(-\\w+)* # optional internal hyphens\n",
      "    | \\$?\\d+(\\.\\d+)? %? # deals with $digit\n",
      "    | \\.\\.\\.\n",
      "    | [][.,;\"'?():-_`]\n",
      "    '''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 178
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print nltk.regexp_tokenize(text,pattern)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['That', 'U.S.A.', 'poster-print', 'costs', '$19.00']\n"
       ]
      }
     ],
     "prompt_number": 179
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 3.8 Segmentation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 180
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Sentence Segmentation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text = nltk.corpus.gutenberg.raw('chesterton-thursday.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sents = sent_tokenizer.tokenize(text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print sents[171:181]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['In the wild events which were to follow this girl had no\\npart at all; he never saw her again until all his tale was over.', 'And yet, in some indescribable way, she kept recurring like a\\nmotive in music through all his mad adventures afterwards, and the\\nglory of her strange hair ran like a red thread through those dark\\nand ill-drawn tapestries of the night.', 'For what followed was so\\nimprobable, that it might well have been a dream.', 'When Syme went out into the starlit street, he found it for the\\nmoment empty.', 'Then he realised (in some odd way) that the silence\\nwas rather a living silence than a dead one.', 'Directly outside the\\ndoor stood a street lamp, whose gleam gilded the leaves of the tree\\nthat bent out over the fence behind him.', 'About a foot from the\\nlamp-post stood a figure almost as rigid and motionless as the\\nlamp-post itself.', 'The tall hat and long frock coat were black; the\\nface, in an abrupt shadow, was almost as dark.', 'Only a fringe of\\nfiery hair against the light, and also something aggressive in the\\nattitude, proclaimed that it was the poet Gregory.', 'He had something\\nof the look of a masked bravo waiting sword in hand for his foe.']\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Word Segmentation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text = \"doyouseethekittyseethedoggydoyoulikethekittylikethedoggy\"\n",
      "seg1 = \"0000000000000001000000000010000000000000000100000000000\"\n",
      "seg2 = \"0100100100100001001001000010100100010010000100010010000\"\n",
      "seg3 = \"0000100100000011001000000110000100010000001100010000001\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def segment(text,segs):\n",
      "    words = []\n",
      "    last = 0\n",
      "    for i in range(len(segs)):\n",
      "        if segs[i] == '1':\n",
      "            words.append(text[last:i+1])\n",
      "            last = i+1\n",
      "    words.append(text[last:])\n",
      "    return words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "segment(text, seg1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedog']"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# segmentation has become a search problem"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def evaluate(text, segmentation):\n",
      "    words = segment(text, segmentation)\n",
      "    text_size = len(words)\n",
      "    lexicon_size = len(' '.join(list(set(words))))\n",
      "    return text_size + lexicon_size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print segment(text, seg3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['doyou', 'see', 'thekitt', 'y', 'see', 'thedogg', 'y', 'doyou', 'like', 'thekitt', 'y', 'like', 'thedogg', 'y']\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate(text,seg3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "46"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate(text,seg2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "47"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate(text,seg1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "63"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from random import randint"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Annealing: searched with phrase with segmentation only, randomly \n",
      "# perturbs zeros and ones proportionate to temperature"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def flip(seg, pos):\n",
      "    return seg[:pos] + str(1-int(seg[pos])) + seg[pos+1:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def flip_n(segs, n):\n",
      "    for i in range(n):\n",
      "        segs = flip(segs, randint(0,len(segs)-1))\n",
      "    return segs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def anneal(text, segs, iterations, cooling_rate):\n",
      "    temperature = float(len(segs))\n",
      "    while temperature > 0.5:\n",
      "        best_segs, best = segs, evaluate(segs, text)\n",
      "        for i in range(iterations):\n",
      "            guess = flip_n(segs, int(round(temperature)))\n",
      "            score = evaluate(text, guess)\n",
      "            if score < best:\n",
      "                best, best_segs = score, guess\n",
      "        score, segs = best, best_segs\n",
      "        temperature = temperature / cooling_rate\n",
      "    print evaluate(text, segs), segment(text,segs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "anneal(text, seg1, 5000, 0.5 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-14-27c50b2c0495>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0manneal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseg1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-13-fbb9011d8bf1>\u001b[0m in \u001b[0;36manneal\u001b[1;34m(text, segs, iterations, cooling_rate)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mbest_segs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msegs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msegs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0mguess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflip_n\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msegs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mguess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mbest\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-2-ba67bf711379>\u001b[0m in \u001b[0;36mflip_n\u001b[1;34m(segs, n)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mflip_n\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msegs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0msegs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msegs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msegs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msegs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\Ruby\\Anaconda\\lib\\random.pyc\u001b[0m in \u001b[0;36mrandint\u001b[1;34m(self, a, b)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \"\"\"\n\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     def _randbelow(self, n, _log=_log, _int=int, _maxwidth=1L<<BPF,\n",
        "\u001b[1;32mC:\\Users\\Ruby\\Anaconda\\lib\\random.pyc\u001b[0m in \u001b[0;36mrandrange\u001b[1;34m(self, start, stop, step, _int, _maxwidth)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;31m# stop argument supplied.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m         \u001b[0mistop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mistop\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"non-integer stop for randrange()\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Lists to Strings"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "from nltk import ConditionalFreqDist\n",
      "fdist = nltk.FreqDist(['dog','cat','dog','cat','snake','dog','cat'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for word in fdist:\n",
      "    print '%s -> %d' %(word, fdist[word]) # called conversion specifiers when we use %"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "cat -> 3\n",
        "dog -> 3\n",
        "snake -> 1\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import brown\n",
      "cfd = ConditionalFreqDist((genre, word)\n",
      "                          for genre in brown.categories()\n",
      "                          for word in brown.words(categories=genre))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "genres = ['news', 'religon', 'hobbies','science_fiction','roamance','humor']\n",
      "modals = ['can', 'could', 'may', 'might', 'must', 'will']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tabulate(cfdist, words, categories):\n",
      "    print '%-16s' % 'Category',\n",
      "    for word in words:\n",
      "        print '%6s' % word,\n",
      "    print \n",
      "    for category in categories:\n",
      "        print '%-16s' % category,\n",
      "        for word in words:\n",
      "            print '%6d' % cfdist[category][word],\n",
      "        print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tabulate(cfd, modals, genres)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Category            can  could    may  might   must   will\n",
        "news                 93     86     66     38     50    389\n",
        "religon               0      0      0      0      0      0\n",
        "hobbies             268     58    131     22     83    264\n",
        "science_fiction      16     49      4     12      8     16\n",
        "roamance              0      0      0      0      0      0\n",
        "humor                16     30      8      8      9     13\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}