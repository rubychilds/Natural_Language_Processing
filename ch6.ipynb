{
 "metadata": {
  "name": "",
  "signature": "sha256:81533dbf24106871f15566237d0e486d56f9e594312f8de7da38621c37bc05ef"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 6.1. Supervised Classification"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Gender identification"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# for feature extraction\n",
      "def gender_features(word):\n",
      "    return {'last_letter': word[-1]} # return is feature set"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gender_features('ruby') # feature values returned should be simple: booleans, numbers, strings"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "{'last_letter': 'y'}"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import names\n",
      "import nltk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "names = ([(name,'male') for name in names.words('male.txt')] + \n",
      "        [(name, 'female') for name in names.words('female.txt')])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "random.shuffle(names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_sets = [(gender_features(name), gender) for name, gender in names]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "size = int(len(feature_sets)*0.8)\n",
      "test_names, training_names = feature_sets[size:], feature_sets[:size]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = nltk.NaiveBayesClassifier.train(training_names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier.classify(gender_features('Ruby'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "'female'"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print nltk.classify.accuracy(classifier,test_names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.769666456891\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier.show_most_informative_features(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Most Informative Features\n",
        "             last_letter = 'k'              male : female =     39.5 : 1.0\n",
        "             last_letter = 'a'            female : male   =     35.4 : 1.0\n",
        "             last_letter = 'v'              male : female =     16.3 : 1.0\n",
        "             last_letter = 'f'              male : female =     14.5 : 1.0\n",
        "             last_letter = 'g'              male : female =     10.3 : 1.0\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def alternative_gender_features(name):\n",
      "    return {'len': len(name), 'first_letter': name[0].lower(), 'last_letter': name[-1].lower()}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alt_feature_sets = [(alternative_gender_features(name), gender) for name, gender in names]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "size = int(len(feature_sets)*0.8)\n",
      "test_names, training_names = alt_feature_sets[size:], alt_feature_sets[:size]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = nltk.NaiveBayesClassifier.train(training_names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print nltk.classify.accuracy(classifier,test_names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.770925110132\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier.show_most_informative_features(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Most Informative Features\n",
        "             last_letter = 'k'              male : female =     39.5 : 1.0\n",
        "             last_letter = 'a'            female : male   =     35.4 : 1.0\n",
        "             last_letter = 'v'              male : female =     16.3 : 1.0\n",
        "             last_letter = 'f'              male : female =     14.5 : 1.0\n",
        "             last_letter = 'g'              male : female =     10.3 : 1.0\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.classify import apply_features\n",
      "train , test = apply_features(gender_features, names[:size]), apply_features(gender_features, names[size:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Choosing the Right Features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def gender_features2(name):\n",
      "    features = {}\n",
      "    features['first_letter'] = name[0].lower()\n",
      "    features['last_letter'] = name[-1].lower()\n",
      "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
      "        features['count(%s)' % letter] = name.lower().count(letter)\n",
      "        features['has(%s)' % letter] = letter in name.lower()\n",
      "    return features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print gender_features2('ruby')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'count(u)': 1, 'has(d)': False, 'count(b)': 1, 'count(w)': 0, 'has(b)': True, 'count(l)': 0, 'count(q)': 0, 'count(n)': 0, 'has(j)': False, 'count(s)': 0, 'count(h)': 0, 'has(h)': False, 'has(y)': True, 'count(j)': 0, 'has(f)': False, 'has(o)': False, 'count(x)': 0, 'has(m)': False, 'count(z)': 0, 'has(k)': False, 'has(u)': True, 'count(d)': 0, 'has(s)': False, 'count(m)': 0, 'count(f)': 0, 'has(q)': False, 'has(w)': False, 'has(e)': False, 'has(z)': False, 'count(t)': 0, 'count(c)': 0, 'has(c)': False, 'has(x)': False, 'count(v)': 0, 'has(a)': False, 'last_letter': 'y', 'has(v)': False, 'count(p)': 0, 'count(o)': 0, 'first_letter': 'r', 'has(i)': False, 'count(i)': 0, 'has(r)': True, 'has(g)': False, 'count(k)': 0, 'count(y)': 1, 'has(n)': False, 'has(l)': False, 'count(e)': 0, 'has(t)': False, 'count(g)': 0, 'count(r)': 1, 'count(a)': 0, 'has(p)': False}\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_sets = [(gender_features2(name), gender) for name, gender in names]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "size = int(len(name)*0.8)\n",
      "train,test = feature_sets[:size], feature_sets[size:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = nltk.NaiveBayesClassifier.train(train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print nltk.classify.accuracy(classifier,test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.533820380401\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Error Analysis\n",
      "* Select development set containing corpus data\n",
      "* then divide into training set and dev-test\n",
      "* dev-test is used for error analysis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_names = names[1500:]\n",
      "test_names = names[:500]\n",
      "dev_names = names[500:1500]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set = [(gender_features(name), gender) for name, gender in train_names]\n",
      "test_set = [(gender_features(name), gender) for name, gender in test_names]\n",
      "dev_set = [(gender_features(name), gender) for name, gender in dev_names]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = nltk.NaiveBayesClassifier.train(train_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "errors = []\n",
      "for name, gender in dev_names:\n",
      "    guess = classifier.classify(gender_features(name.lower()))\n",
      "    if guess != gender:\n",
      "        errors.append((gender,guess,name))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for gender, guess, name in sorted(errors)[:10]:\n",
      "    print 'correct: %s  guess: %s  name: %s' % (gender, guess, name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "correct: female  guess: male  name: Alis\n",
        "correct: female  guess: male  name: Allsun\n",
        "correct: female  guess: male  name: Alyson\n",
        "correct: female  guess: male  name: Amargo\n",
        "correct: female  guess: male  name: Arlyn\n",
        "correct: female  guess: male  name: Avrit\n",
        "correct: female  guess: male  name: Barb\n",
        "correct: female  guess: male  name: Cam\n",
        "correct: female  guess: male  name: Caren\n",
        "correct: female  guess: male  name: Carlynn\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def gender_features(name):\n",
      "    return {'suf1': name[-1], 'suff2': name[-2]}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train = [(gender_features(name),gender) for name, gender in train_names]\n",
      "test = [(gender_features(name),gender) for name, gender in test_names]\n",
      "dev = [(gender_features(name),gender) for name, gender in dev_names]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = nltk.NaiveBayesClassifier.train(train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print nltk.classify.accuracy(classifier,test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.768\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Document Classification"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import movie_reviews\n",
      "import random\n",
      "import nltk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "documents = [(list(movie_reviews.words(fileid)), category)\n",
      "             for category in movie_reviews.categories()\n",
      "             for fileid in movie_reviews.fileids(category)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "random.shuffle(documents)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word_features = all_words.keys()[:2000]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def document_features(document):\n",
      "    document_words = set(document) # chcecking if word ina set is faster than a list\n",
      "    features = {}\n",
      "    for word in word_features:\n",
      "        features[word] = word in document\n",
      "    return features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_sets = [(document_features(d),c) for d,c in documents]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set, test_set = feature_sets[100:], feature_sets[:100]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = nltk.NaiveBayesClassifier.train(train_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print nltk.classify.accuracy(classifier, test_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.87\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier.show_most_informative_features(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Most Informative Features\n",
        "             outstanding = True              pos : neg    =     10.9 : 1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "                   mulan = True              pos : neg    =      8.9 : 1.0\n",
        "                  seagal = True              neg : pos    =      7.4 : 1.0\n",
        "             wonderfully = True              pos : neg    =      7.0 : 1.0\n",
        "                   damon = True              pos : neg    =      6.3 : 1.0\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Part of Speech Tagging"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import brown"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "suffix_fdist = nltk.FreqDist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for word in brown.words():\n",
      "    word = word.lower()\n",
      "    suffix_fdist.inc(word[-1:])\n",
      "    suffix_fdist.inc(word[-2:])\n",
      "    suffix_fdist.inc(word[-3:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "common_sufs = suffix_fdist.keys()[:100]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print common_sufs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['e', ',', '.', 's', 'd', 't', 'he', 'n', 'a', 'of', 'the', 'y', 'r', 'to', 'in', 'f', 'o', 'ed', 'nd', 'is', 'on', 'l', 'g', 'and', 'ng', 'er', 'as', 'ing', 'h', 'at', 'es', 'or', 're', 'it', '``', 'an', \"''\", 'm', ';', 'i', 'ly', 'ion', 'en', 'al', '?', 'nt', 'be', 'hat', 'st', 'his', 'th', 'll', 'le', 'ce', 'by', 'ts', 'me', 've', \"'\", 'se', 'ut', 'was', 'for', 'ent', 'ch', 'k', 'w', 'ld', '`', 'rs', 'ted', 'ere', 'her', 'ne', 'ns', 'ith', 'ad', 'ry', ')', '(', 'te', '--', 'ay', 'ty', 'ot', 'p', 'nce', \"'s\", 'ter', 'om', 'ss', ':', 'we', 'are', 'c', 'ers', 'uld', 'had', 'so', 'ey']\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pos_features(word):\n",
      "    features = {}\n",
      "    for suffix in common_sufs:\n",
      "        features[suffix] = word.lower().endswith(suffix)\n",
      "    return features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tagged_words = brown.tagged_words(categories='news')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_sets = [(pos_features(word),c) for word, c in tagged_words]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "size = int(len(feature_sets)*0.9)\n",
      "print size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "90498\n"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set, test_set = feature_sets[:size], feature_sets[size:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = nltk.DecisionTreeClassifier.train(train_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier.classify(pos_features('cats'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 76,
       "text": [
        "'NNS'"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print classifier.pseudocode(depth=4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "if the == False: \n",
        "  if , == False: \n",
        "    if s == False: \n",
        "      if . == False: return 'NP-HL'\n",
        "      if . == True: return '.'\n",
        "    if s == True: \n",
        "      if was == False: return 'NNS'\n",
        "      if was == True: return 'BEDZ'\n",
        "  if , == True: return ','\n",
        "if the == True: return 'AT'\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print nltk.classify.accuracy(classifier, test_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.626889419252\n"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exploiting Context"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Can extend feature extraction function to look at length of word, number of syllales, prefix etc\n",
      "* No way to add features with context words appears in.\n",
      "* As an alternative can pass in untagged sentence along with index of target word"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pos_features(sentence,i):\n",
      "    features = { \n",
      "                \"suf(1)\": sentence[i][-1:],\n",
      "                \"suf(2)\": sentence[i][-2:],\n",
      "                \"suf(3)\": sentence[i][-3:]\n",
      "    }\n",
      "    if i ==0:\n",
      "        features[\"prev_word\"] = \"<START>\"\n",
      "    else:\n",
      "        features[\"prev_word\"] = sentence[i-1]\n",
      "    return features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos_features(brown.sents()[0], 8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 60,
       "text": [
        "{'prev_word': 'an', 'suf(1)': 'n', 'suf(2)': 'on', 'suf(3)': 'ion'}"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tagged_sents = brown.tagged_sents(categories='news')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "featuresets = []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for tagged_sent in tagged_sents:\n",
      "    untagged_sent = nltk.tag.untag(tagged_sent)\n",
      "    for i, (word,tag) in enumerate(tagged_sent):\n",
      "        featuresets.append((pos_features(untagged_sent,i),tag ))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "size = int(len(featuresets)*0.9)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set, test_set = featuresets[:size], featuresets[size:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = nltk.NaiveBayesClassifier.train(train_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print nltk.classify.accuracy(classifier,test_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.777247414479\n"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Using contextual features can increase pos tagger\n",
      "* Classifier can learn if a noun follows a specific adjective etc but unable to generalise this to all words following an adjective are nouns"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Sequence Classification"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Use joint classifier methods which choose appropriate label for related inputs\n",
      "* Consecutive classification/ Greedy Sequence classification: to find most likely label for first input, then use this as a helper for the next input etc. Continues until all inputs are labelled\n",
      "* Used for bigram tagger which choses pos tag for first word then tag for subsequent word\n",
      "* Feature extractor to take history parameter whicih provides list of tages predicted so far\n",
      "* History corresponds to word in sentence that are to the left of current word and already tagged. Can't look at right words as untagged"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pos_features(sentence, i, history): [1]\n",
      "     features = {\"suffix(1)\": sentence[i][-1:],\n",
      "                 \"suffix(2)\": sentence[i][-2:],\n",
      "                 \"suffix(3)\": sentence[i][-3:]}\n",
      "     if i == 0:\n",
      "         features[\"prev-word\"] = \"<START>\"\n",
      "         features[\"prev-tag\"] = \"<START>\"\n",
      "     else:\n",
      "         features[\"prev-word\"] = sentence[i-1]\n",
      "         features[\"prev-tag\"] = history[i-1]\n",
      "     return features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class ConsecutivePosTagger(nltk.TaggerI):\n",
      "\n",
      "    def __init__(self, train_sents):\n",
      "        train_set = []\n",
      "        for tagged_sent in train_sents:\n",
      "            untagged_sent = nltk.tag.untag(tagged_sent)\n",
      "            history = []\n",
      "            for i, (word, tag) in enumerate(tagged_sent):\n",
      "                featureset = pos_features(untagged_sent, i, history)\n",
      "                train_set.append( (featureset, tag) )\n",
      "                history.append(tag)\n",
      "        self.classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
      "\n",
      "    def tag(self, sentence):\n",
      "        history = []\n",
      "        for i, word in enumerate(sentence):\n",
      "            featureset = pos_features(sentence, i, history)\n",
      "            tag = self.classifier.classify(featureset)\n",
      "            history.append(tag)\n",
      "        return zip(sentence, history)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tagged_sents = brown.tagged_sents(categories= 'news')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "size = int(len(tagged_sents)*0.9)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 116
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train, test = tagged_sents[:size], tagged_sents[size:]\n",
      "print len(train), len(test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4160 463\n"
       ]
      }
     ],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tagger = ConsecutivePosTagger(train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 118
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print tagger.evaluate(test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.787002890461\n"
       ]
      }
     ],
     "prompt_number": 119
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Other Methods for Sequence Classification"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Previously commit ot every decision made - an incorrect label hass an impact going forward\n",
      "* Can use transformational strategies - create inital assignent then iteativeky refine assignment to remove inconsistencies\n",
      "* Can assign scores to possible seq of pos and choose highest scoring seq\n",
      "* Hidden Markov Models: use predicted tags but instead of finding single best tag, they create probabilities for all tags -> combined to create prob scores for sequences and highest score is chosen\n",
      "* HMM - require only to look at most recent tag. Dynamic programme to find most likely tag seq\n",
      "* Maximum entropy markov modeks\n",
      "* Linear chain conditional random field models"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 6.2 Further Supervised Classification"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Sentence segmentation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Classification task for punctuation\n",
      "* Symbol to end sentence\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sents = nltk.corpus.treebank_raw.sents()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 120
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokens = []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 121
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "boundaries = set()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 122
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "offset = 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 123
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for sent in sents:\n",
      "    tokens.extend(sent)\n",
      "    offset += len(sent)\n",
      "    boundaries.add(offset-1) # boundaries is a set containing indexes of all sentence boundary tokens"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def punct_features(tokens,i): # tokens is merged list of sentences\n",
      "    return {'next_word_cap': tokens[i+1][0].isupper(),\n",
      "            'prevword': tokens[i-1].lower(),\n",
      "            'punct': tokens[i],\n",
      "            'prev_word_is_on_char': len(tokens[i-1])==1\n",
      "            }"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_sets = [(punct_features(tokens,i), (i in boundaries))\n",
      "                for i in range(1,len(tokens)-1)\n",
      "                if tokens[i]in '.!?']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}