{
 "metadata": {
  "name": "",
  "signature": "sha256:ea44767e7e81bae85f5f7cc2d778467434e2d04ad396ad2c5690be6aa662bad7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 6.1. Supervised Classification"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Gender identification"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# for feature extraction\n",
      "def gender_features(word):\n",
      "    return {'last_letter': word[-1]} # return is feature set"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gender_features('ruby') # feature values returned should be simple: booleans, numbers, strings"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "{'last_letter': 'y'}"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import names\n",
      "import nltk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "names = ([(name,'male') for name in names.words('male.txt')] + \n",
      "        [(name, 'female') for name in names.words('female.txt')])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "random.shuffle(names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_sets = [(gender_features(name), gender) for name, gender in names]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "size = int(len(feature_sets)*0.8)\n",
      "test_names, training_names = feature_sets[size:], feature_sets[:size]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = nltk.NaiveBayesClassifier.train(training_names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier.classify(gender_features('Ruby'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "'female'"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print nltk.classify.accuracy(classifier,test_names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.769666456891\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier.show_most_informative_features(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Most Informative Features\n",
        "             last_letter = 'k'              male : female =     39.5 : 1.0\n",
        "             last_letter = 'a'            female : male   =     35.4 : 1.0\n",
        "             last_letter = 'v'              male : female =     16.3 : 1.0\n",
        "             last_letter = 'f'              male : female =     14.5 : 1.0\n",
        "             last_letter = 'g'              male : female =     10.3 : 1.0\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def alternative_gender_features(name):\n",
      "    return {'len': len(name), 'first_letter': name[0].lower(), 'last_letter': name[-1].lower()}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alt_feature_sets = [(alternative_gender_features(name), gender) for name, gender in names]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "size = int(len(feature_sets)*0.8)\n",
      "test_names, training_names = alt_feature_sets[size:], alt_feature_sets[:size]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = nltk.NaiveBayesClassifier.train(training_names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print nltk.classify.accuracy(classifier,test_names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.770925110132\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier.show_most_informative_features(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Most Informative Features\n",
        "             last_letter = 'k'              male : female =     39.5 : 1.0\n",
        "             last_letter = 'a'            female : male   =     35.4 : 1.0\n",
        "             last_letter = 'v'              male : female =     16.3 : 1.0\n",
        "             last_letter = 'f'              male : female =     14.5 : 1.0\n",
        "             last_letter = 'g'              male : female =     10.3 : 1.0\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.classify import apply_features\n",
      "train , test = apply_features(gender_features, names[:size]), apply_features(gender_features, names[size:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Choosing the Right Features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def gender_features2(name):\n",
      "    features = {}\n",
      "    features['first_letter'] = name[0].lower()\n",
      "    features['last_letter'] = name[-1].lower()\n",
      "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
      "        features['count(%s)' % letter] = name.lower().count(letter)\n",
      "        features['has(%s)' % letter] = letter in name.lower()\n",
      "    return features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print gender_features2('ruby')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'count(u)': 1, 'has(d)': False, 'count(b)': 1, 'count(w)': 0, 'has(b)': True, 'count(l)': 0, 'count(q)': 0, 'count(n)': 0, 'has(j)': False, 'count(s)': 0, 'count(h)': 0, 'has(h)': False, 'has(y)': True, 'count(j)': 0, 'has(f)': False, 'has(o)': False, 'count(x)': 0, 'has(m)': False, 'count(z)': 0, 'has(k)': False, 'has(u)': True, 'count(d)': 0, 'has(s)': False, 'count(m)': 0, 'count(f)': 0, 'has(q)': False, 'has(w)': False, 'has(e)': False, 'has(z)': False, 'count(t)': 0, 'count(c)': 0, 'has(c)': False, 'has(x)': False, 'count(v)': 0, 'has(a)': False, 'last_letter': 'y', 'has(v)': False, 'count(p)': 0, 'count(o)': 0, 'first_letter': 'r', 'has(i)': False, 'count(i)': 0, 'has(r)': True, 'has(g)': False, 'count(k)': 0, 'count(y)': 1, 'has(n)': False, 'has(l)': False, 'count(e)': 0, 'has(t)': False, 'count(g)': 0, 'count(r)': 1, 'count(a)': 0, 'has(p)': False}\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_sets = [(gender_features2(name), gender) for name, gender in names]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "size = int(len(name)*0.8)\n",
      "train,test = feature_sets[:size], feature_sets[size:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = nltk.NaiveBayesClassifier.train(train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print nltk.classify.accuracy(classifier,test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.533820380401\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Error Analysis\n",
      "* Select development set containing corpus data\n",
      "* then divide into training set and dev-test\n",
      "* dev-test is used for error analysis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_names = names[1500:]\n",
      "test_names = names[:500]\n",
      "dev_names = names[500:1500]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set = [(gender_features(name), gender) for name, gender in train_names]\n",
      "test_set = [(gender_features(name), gender) for name, gender in test_names]\n",
      "dev_set = [(gender_features(name), gender) for name, gender in dev_names]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = nltk.NaiveBayesClassifier.train(train_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "errors = []\n",
      "for name, gender in dev_names:\n",
      "    guess = classifier.classify(gender_features(name.lower()))\n",
      "    if guess != gender:\n",
      "        errors.append((gender,guess,name))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for gender, guess, name in sorted(errors)[:10]:\n",
      "    print 'correct: %s  guess: %s  name: %s' % (gender, guess, name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "correct: female  guess: male  name: Alis\n",
        "correct: female  guess: male  name: Allsun\n",
        "correct: female  guess: male  name: Alyson\n",
        "correct: female  guess: male  name: Amargo\n",
        "correct: female  guess: male  name: Arlyn\n",
        "correct: female  guess: male  name: Avrit\n",
        "correct: female  guess: male  name: Barb\n",
        "correct: female  guess: male  name: Cam\n",
        "correct: female  guess: male  name: Caren\n",
        "correct: female  guess: male  name: Carlynn\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def gender_features(name):\n",
      "    return {'suf1': name[-1], 'suff2': name[-2]}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train = [(gender_features(name),gender) for name, gender in train_names]\n",
      "test = [(gender_features(name),gender) for name, gender in test_names]\n",
      "dev = [(gender_features(name),gender) for name, gender in dev_names]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = nltk.NaiveBayesClassifier.train(train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print nltk.classify.accuracy(classifier,test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.768\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Document Classification"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import movie_reviews\n",
      "import random\n",
      "import nltk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "documents = [(list(movie_reviews.words(fileid)), category)\n",
      "             for category in movie_reviews.categories()\n",
      "             for fileid in movie_reviews.fileids(category)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "random.shuffle(documents)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word_features = all_words.keys()[:2000]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def document_features(document):\n",
      "    document_words = set(document) # chcecking if word ina set is faster than a list\n",
      "    features = {}\n",
      "    for word in word_features:\n",
      "        features[word] = word in document\n",
      "    return features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_sets = [(document_features(d),c) for d,c in documents]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set, test_set = feature_sets[100:], feature_sets[:100]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = nltk.NaiveBayesClassifier.train(train_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print nltk.classify.accuracy(classifier, test_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.87\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier.show_most_informative_features(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Most Informative Features\n",
        "             outstanding = True              pos : neg    =     10.9 : 1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "                   mulan = True              pos : neg    =      8.9 : 1.0\n",
        "                  seagal = True              neg : pos    =      7.4 : 1.0\n",
        "             wonderfully = True              pos : neg    =      7.0 : 1.0\n",
        "                   damon = True              pos : neg    =      6.3 : 1.0\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Part of Speech Tagging"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import brown"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "suffix_fdist = nltk.FreqDist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for word in brown.words():\n",
      "    word = word.lower()\n",
      "    suffix_fdist.inc(word[-1:])\n",
      "    suffix_fdist.inc(word[-2:])\n",
      "    suffix_fdist.inc(word[-3:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "common_sufs = suffix_fdist.keys()[:100]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print common_sufs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['e', ',', '.', 's', 'd', 't', 'he', 'n', 'a', 'of', 'the', 'y', 'r', 'to', 'in', 'f', 'o', 'ed', 'nd', 'is', 'on', 'l', 'g', 'and', 'ng', 'er', 'as', 'ing', 'h', 'at', 'es', 'or', 're', 'it', '``', 'an', \"''\", 'm', ';', 'i', 'ly', 'ion', 'en', 'al', '?', 'nt', 'be', 'hat', 'st', 'his', 'th', 'll', 'le', 'ce', 'by', 'ts', 'me', 've', \"'\", 'se', 'ut', 'was', 'for', 'ent', 'ch', 'k', 'w', 'ld', '`', 'rs', 'ted', 'ere', 'her', 'ne', 'ns', 'ith', 'ad', 'ry', ')', '(', 'te', '--', 'ay', 'ty', 'ot', 'p', 'nce', \"'s\", 'ter', 'om', 'ss', ':', 'we', 'are', 'c', 'ers', 'uld', 'had', 'so', 'ey']\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pos_features(word):\n",
      "    features = {}\n",
      "    for suffix in common_sufs:\n",
      "        features[suffix] = word.lower().endswith(suffix)\n",
      "    return features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tagged_words = brown.tagged_words(categories='news')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_sets = [(pos_features(word),c) for word, c in tagged_words]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "size = int(len(feature_sets)*0.9)\n",
      "print size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "90498\n"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set, test_set = feature_sets[:size], feature_sets[size:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = nltk.DecisionTreeClassifier.train(train_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier.classify(pos_features('cats'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 76,
       "text": [
        "'NNS'"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print classifier.pseudocode(depth=4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "if the == False: \n",
        "  if , == False: \n",
        "    if s == False: \n",
        "      if . == False: return 'NP-HL'\n",
        "      if . == True: return '.'\n",
        "    if s == True: \n",
        "      if was == False: return 'NNS'\n",
        "      if was == True: return 'BEDZ'\n",
        "  if , == True: return ','\n",
        "if the == True: return 'AT'\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print nltk.classify.accuracy(classifier, test_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.626889419252\n"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exploiting Context"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Can extend feature extraction function to look at length of word, number of syllales, prefix etc\n",
      "* No way to add features with context words appears in.\n",
      "* As an alternative can pass in untagged sentence along with index of target word"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pos_features(sentence,i):\n",
      "    features = { \n",
      "                \"suf(1)\": sentence[i][-1:],\n",
      "                \"suf(2)\": sentence[i][-2:],\n",
      "                \"suf(3)\": sentence[i][-3:]\n",
      "    }\n",
      "    if i ==0:\n",
      "        features[\"prev_word\"] = \"<START>\"\n",
      "    else:\n",
      "        features[\"prev_word\"] = sentence[i-1]\n",
      "    return features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos_features(brown.sents()[0], 8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 60,
       "text": [
        "{'prev_word': 'an', 'suf(1)': 'n', 'suf(2)': 'on', 'suf(3)': 'ion'}"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tagged_sents = brown.tagged_sents(categories='news')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "featuresets = []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for tagged_sent in tagged_sents:\n",
      "    untagged_sent = nltk.tag.untag(tagged_sent)\n",
      "    for i, (word,tag) in enumerate(tagged_sent):\n",
      "        featuresets.append((pos_features(untagged_sent,i),tag ))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "size = int(len(featuresets)*0.9)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set, test_set = featuresets[:size], featuresets[size:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = nltk.NaiveBayesClassifier.train(train_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print nltk.classify.accuracy(classifier,test_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.777247414479\n"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Using contextual features can increase pos tagger\n",
      "* Classifier can learn if a noun follows a specific adjective etc but unable to generalise this to all words following an adjective are nouns"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Sequence Classification"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Use joint classifier methods which choose appropriate label for related inputs\n",
      "* Consecutive classification/ Greedy Sequence classification: to find most likely label for first input, then use this as a helper for the next input etc. Continues until all inputs are labelled\n",
      "* Used for bigram tagger which choses pos tag for first word then tag for subsequent word\n",
      "* Feature extractor to take history parameter whicih provides list of tages predicted so far\n",
      "* History corresponds to word in sentence that are to the left of current word and already tagged. Can't look at right words as untagged"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pos_features(sentence, i, history): [1]\n",
      "     features = {\"suffix(1)\": sentence[i][-1:],\n",
      "                 \"suffix(2)\": sentence[i][-2:],\n",
      "                 \"suffix(3)\": sentence[i][-3:]}\n",
      "     if i == 0:\n",
      "         features[\"prev-word\"] = \"<START>\"\n",
      "         features[\"prev-tag\"] = \"<START>\"\n",
      "     else:\n",
      "         features[\"prev-word\"] = sentence[i-1]\n",
      "         features[\"prev-tag\"] = history[i-1]\n",
      "     return features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class ConsecutivePosTagger(nltk.TaggerI):\n",
      "\n",
      "    def __init__(self, train_sents):\n",
      "        train_set = []\n",
      "        for tagged_sent in train_sents:\n",
      "            untagged_sent = nltk.tag.untag(tagged_sent)\n",
      "            history = []\n",
      "            for i, (word, tag) in enumerate(tagged_sent):\n",
      "                featureset = pos_features(untagged_sent, i, history)\n",
      "                train_set.append( (featureset, tag) )\n",
      "                history.append(tag)\n",
      "        self.classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
      "\n",
      "    def tag(self, sentence):\n",
      "        history = []\n",
      "        for i, word in enumerate(sentence):\n",
      "            featureset = pos_features(sentence, i, history)\n",
      "            tag = self.classifier.classify(featureset)\n",
      "            history.append(tag)\n",
      "        return zip(sentence, history)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tagged_sents = brown.tagged_sents(categories= 'news')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "size = int(len(tagged_sents)*0.9)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 116
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train, test = tagged_sents[:size], tagged_sents[size:]\n",
      "print len(train), len(test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4160 463\n"
       ]
      }
     ],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tagger = ConsecutivePosTagger(train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 118
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print tagger.evaluate(test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.787002890461\n"
       ]
      }
     ],
     "prompt_number": 119
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Other Methods for Sequence Classification"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Previously commit ot every decision made - an incorrect label hass an impact going forward\n",
      "* Can use transformational strategies - create inital assignent then iteativeky refine assignment to remove inconsistencies\n",
      "* Can assign scores to possible seq of pos and choose highest scoring seq\n",
      "* Hidden Markov Models: use predicted tags but instead of finding single best tag, they create probabilities for all tags -> combined to create prob scores for sequences and highest score is chosen\n",
      "* HMM - require only to look at most recent tag. Dynamic programme to find most likely tag seq\n",
      "* Maximum entropy markov modeks\n",
      "* Linear chain conditional random field models"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 6.2 Further Supervised Classification"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Sentence segmentation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Classification task for punctuation\n",
      "* Symbol to end sentence\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sents = nltk.corpus.treebank_raw.sents()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokens = []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "boundaries = set()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "offset = 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for sent in sents:\n",
      "    tokens.extend(sent)\n",
      "    offset += len(sent)\n",
      "    boundaries.add(offset-1) # boundaries is a set containing indexes of all sentence boundary tokens"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def punct_features(tokens,i): # tokens is merged list of sentences\n",
      "    return {'next_word_cap': tokens[i+1][0].isupper(),\n",
      "            'prevword': tokens[i-1].lower(),\n",
      "            'punct': tokens[i],\n",
      "            'prev_word_is_on_char': len(tokens[i-1])==1\n",
      "            }"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_sets = [(punct_features(tokens,i), (i in boundaries))\n",
      "                for i in range(1,len(tokens)-1)\n",
      "                if tokens[i]in '.!?']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print feature_sets[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[({'punct': '.', 'prev_word_is_on_char': False, 'next_word_cap': False, 'prevword': 'nov'}, False), ({'punct': '.', 'prev_word_is_on_char': False, 'next_word_cap': True, 'prevword': '29'}, True), ({'punct': '.', 'prev_word_is_on_char': False, 'next_word_cap': True, 'prevword': 'mr'}, False), ({'punct': '.', 'prev_word_is_on_char': True, 'next_word_cap': True, 'prevword': 'n'}, False), ({'punct': '.', 'prev_word_is_on_char': False, 'next_word_cap': False, 'prevword': 'group'}, True), ({'punct': '.', 'prev_word_is_on_char': True, 'next_word_cap': True, 'prevword': '.'}, False), ({'punct': '.', 'prev_word_is_on_char': False, 'next_word_cap': False, 'prevword': 'conglomerate'}, True), ({'punct': '.', 'prev_word_is_on_char': True, 'next_word_cap': True, 'prevword': '.'}, False), ({'punct': '.', 'prev_word_is_on_char': False, 'next_word_cap': True, 'prevword': 'reported'}, True), ({'punct': '.', 'prev_word_is_on_char': False, 'next_word_cap': True, 'prevword': 'said'}, True)]\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "size = int(len(feature_sets)*0.9)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train, test = feature_sets[:size], feature_sets[:size]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = nltk.NaiveBayesClassifier.train(train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.classify.accuracy(classifier,train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "0.9681232091690545"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def segment_sentences(words):\n",
      "    start = 0\n",
      "    sents = []\n",
      "    for i , word in enumerate(words): # check if labelled as boundary,\n",
      "        if word in '.!?' and classifier.classify(punct_features(words,i)) == True:\n",
      "            sents.append(words[start:i+1])\n",
      "            start = i+1\n",
      "    if start < len(words):\n",
      "        sents.append(words[start:])\n",
      "    return sents"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Identifying Dialogue Act Types"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Utterances are a type of action performed by the speaker\n",
      "* Recogonising dialogue acts as actions can help in understanding what a person means\n",
      "* NPS chat has different act types so can build a classifier to recognise the different types"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "posts  = nltk.corpus.nps_chat.xml_posts()[:10000]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def dialogue_act(post):\n",
      "    features = {}\n",
      "    for word in nltk.word_tokenize(post):\n",
      "        features['%s'%word.lower()] = True\n",
      "    return features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_sets = [(dialogue_act(post.text), post.get('class')) \n",
      "                for post in posts]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print feature_sets[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[({'name': True, 'gay': True, 'this': True, 'im': True, 'now': True, 'with': True, 'left': True}, 'Statement'), ({'p': True, ':': True}, 'Emotion'), ({'part': True}, 'System'), ({'everyone': True, 'hey': True}, 'Greet'), ({'ah': True, 'well': True}, 'Statement'), ({'nick': True, ':10-19-20suser7': True}, 'System'), ({'a': True, 'name': True, 'gay': True, 'is': True, '.': True, '10-19-20suser7': True}, 'Accept'), ({'a': True, 'golf': True, '.': True, '10-19-20suser121': True, '.action': True, 'clap': True, 'gives': True}, 'System'), ({')': True, ':': True}, 'Emotion'), ({'join': True}, 'System')]\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "size = int(len(feature_sets)*0.9)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train,test = feature_sets[:size], feature_sets[size:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = nltk.NaiveBayesClassifier.train(train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print nltk.classify.accuracy(classifier, test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.713\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Recognizing Textual Entailment"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* RTE: determines if a piece of text T entails the hypothesis\n",
      "* Relationship between text and hyp. is not intended to be a logical entailment\n",
      "* Can treat as classification task, as does seems we would use a combination of semantics, parsing, real-wrold knowledge etc.\n",
      "* If there is text absent in entailment but in hyp. there will be no entailment"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In following extractor, words act as proxies for information and features count degree of word overlap and amount there are words in hyp not in text"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def rte_features(rte_pair):\n",
      "    extractor = nltk.RTEFeatureExtractor(rte_pair)\n",
      "    features = {}\n",
      "    features['word_overlap'] = len(extractor.overlap('word'))\n",
      "    features['word_hyp_extra'] = len(extractor.hyp_extra('word'))\n",
      "    features['ne_overlap'] = len(extractor.overlap('ne'))\n",
      "    features['ne_hyp_extra'] = len(extractor.hyp_extra('ne'))\n",
      "    return features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rte_pair = nltk.corpus.rte.pairs(['rte3_dev.xml'])[33]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "extractor = nltk.RTEFeatureExtractor(rte_pair)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print extractor.text_words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "set(['Russia', 'Organisation', 'Shanghai', 'Asia', 'four', 'at', 'operation', 'SCO', 'Iran', 'Soviet', 'Davudi', 'fight', 'China', 'association', 'fledgling', 'terrorism', 'was', 'that', 'republics', 'Co', 'representing', 'former', 'Parviz', 'central', 'meeting', 'together', 'binds'])\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "print extractor.hyp_words"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print extractor.overlap('word')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "set([])\n"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print extractor.overlap('ne')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "set(['SCO', 'China'])\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features = [rte_features(pair) for pair in nltk.corpus.rte.pairs('rte3_dev.xml')]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Scaling up to Large Datasets"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* summary: use C"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 6.3 Evaluation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Test Set"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Compare inputs for test set with correct labels\n",
      "* Same format as training set\n",
      "* Test set should be distinct from training\n",
      "* Trade-off between test amount and training amount of data\n",
      "* For classification tasks with a small number of well balanced labels and diverse test set, we can use around 100 training examples\n",
      "* If large number of labels then we need to ensure trainning set has around 50 of the infrequent labels\n",
      "* If closely related instances such as being drawn from same document then increase test set to ensure lack of diversity doesn't skew results\n",
      "* The more similar test and training sets are the less ocnfidence we can be evaluation resulst will generalise eg. the pos tagging classification taks using the Brown corpus\n",
      "* Test set can contain training examples due to random.shuffle() call. If there is any consistency in document then this is refelected in both dev and test sets\n",
      "* Could draw examples from two catergories or more ti be more confident clasifier generalises well beyond data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Accuracy"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Measures the percentage of inputs in test set correctly labeled. \n",
      "* nltk.classify.accuracy(classify, train_set)\n",
      "* Consider frequencies of different classes in train set when calculating accouracy\n",
      "* Evaluate on a balanced corpus"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Precision and Recall"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Confusion Matrices"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* cells [i,j] where it shows how often label j was predicted when the correct label is i. Diagonal shows correct entries"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tag_list(tagged_sents):\n",
      "    return [tag for sent in tagged_sents for word, tag in sent]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def apply_tagger(tagger, sents):\n",
      "    return [tagger.tag(nltk.tag.untag(sent)) for sent in sents]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gold = tag_list(nltk.corpus.brown.tagged_sents(categories='news'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#t2 is a built classifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test = tag_list(apply_tagger(t2, nltk.corpus.brown.tagged_sents(categories='news')))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cm = nltk.ConfusionMatrix(gold,test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Cross Validation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Have to balance test and training sets, as if test too large, there isn't enough training\n",
      "* Can perform multiple evaluations on different test sets then combine scores\n",
      "* Divide original corpus into N subsets -> Folds\n",
      "* Train classifier on data exc. fold each time\n",
      "* Fold maybe too small to evaluate on its own but combining scores is more reliable\n",
      "* Also allows us to examine performance variation across training sets - if same throughout we can be confident, if not we are skeptical"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 6.4 Decision Trees"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Flowchart selecting labels for input values\n",
      "* Decision nodes - check feature values\n",
      "* Leaf nodes - assign labels\n",
      "* Root node - initial decision node\n",
      "* Decision stump - decision tree with single decision node. One leaf for each feature then decide what produces higher accuracy\n",
      "* Select overall best stump then check accuracy for each leaf. If not high enough, replace this with another stump to grow a decision tree"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Entropy and Information Gain"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Information gain shows how much more organised input values become when we divide them up\n",
      "* We calculate entropy per label, which will be high if input values have highely varied labels\n",
      "* Entropy ![](http://upload.wikimedia.org/math/8/7/e/87efdf0d38947240683250d3a24466e0.png)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def entropy(labels):\n",
      "    freqdist = nltk.FreqDist(labels)\n",
      "    probs = [freqdist.freq(l) for l in nltk.FreqDist(labels)]\n",
      "    return -sum([p*math.log(p,2) for p in probs])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print entropy(['male','male','male','male'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-0.0\n"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print entropy(['male','female','male','male'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.811278124459\n"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print entropy(['male','female','male','female'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.0\n"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print entropy(['female','female','female','female'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-0.0\n"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Calcuate entropy of labels to determine how to organise labels once applying decision stump\n",
      "* Calculate decision tree leaves entropy and take average\n",
      "* Information gain, is initial entropy minus new entropy\n",
      "* Higher information gain the better the decision stump does to divide input vals into coherant stumps\n",
      "* Must consider efficiency: the algo for selecting dec stump constructs candidate dec stump for every feature and this is repeated\n",
      "* Can reuse info previously calculated \n",
      "* Simple to use, easy to interpret, suitable to cases of hieracial categorical distinctions can be made\n",
      "* Branch splits data, so data examples becomes smaller and smaller. Lower decisions can overfit data that reflect idosyncrasies of data rather than linguistically significant patterns\n",
      "* Must prune decision nodes to reduce overfit\n",
      "* Force feature checking in certain order even when features may act indep. of each other"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 6.5 Naive Bayes Classification"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* To choose label for input, we calculate prior probability of each label determined by checking frequency of each label in training\n",
      "* The prob of each feature is combined with priori prib to obtain a likelihood est for each label\n",
      "* The highest likelihood est label is assigned\n",
      "* Individual features vote against labels that don't occur with feature often\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Underlying Probablistic Model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* NB chooses most likely label for input, under assumption every input is generated by choosing class label for that input, then generating each feature independent of others - NB assumption\n",
      "* Features, are often dependent on one another\n",
      "* Calculate expression for P(label|features), choose l that maximises P(l|features) = P(features|label)/P(features)\n",
      "* P(features) -> same for every label = sum(P(features,label_i))\n",
      "* P(features, label) = p(label)* P(features|label)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Zero Counts and Smoothing\n",
      "* "
     ]
    }
   ],
   "metadata": {}
  }
 ]
}